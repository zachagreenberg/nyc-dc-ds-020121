{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sampling and the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda \n",
    "\n",
    "SWBAT:\n",
    "- Differentiate between population and sample;\n",
    "- Define and calculate standard error;\n",
    "- Use `numpy` to randomly sample a distribution;\n",
    "- Describe the Central Limit Theorem and connect it to our knowledge of distributions and sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive vs Inferential Statistics\n",
    "\n",
    "- Descriptive Statistics\n",
    "   > Simply describe what is observed. The average height of a player on a high school football team can be directly calculated by measuring all of the current players' heights.\n",
    "  \n",
    "- Inferential statistics \n",
    "    > Say something general about a larger group of subjects than those we have measured. For example, we would be doing inferential statistics if we used the information about our team above to say something about the average height of *all* high school football players.\n",
    "\n",
    "    - To put it another way, statistical inference is the process by which we take observations of a subset of a group and generalize to the whole group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Population Inference\n",
    "\n",
    "The mayor's office has hired Flatiron Data Science Immersive students to determine a way to fix traffic congestion. A good starting point is to determine what proportion of the population of Seattle owns a car.\n",
    "\n",
    "In order for us to make any determinations about a population, we must first get information about it.\n",
    "\n",
    "Because it's usually completely impractical to get data about *everyone* in a population, we must take a sample.\n",
    "\n",
    "### Key Terms\n",
    "\n",
    " - the entire group is known as the **population**  \n",
    " - the subset is a known as the **sample**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pop](./img/sample_pop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We would use samples if the population is:\n",
    "    - Too big to enumerate\n",
    "    - too difficult/time consuming or expensive to sample in its entirety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random sampling is not easy to do**  \n",
    "Continuing our Seattle car example, how would we take a sample? \n",
    "\n",
    "Here are two strategies we might employ:\n",
    "\n",
    "* Stand outside of Flatiron at 12 pm and ask random people until *n* responses\n",
    "\n",
    "\n",
    "* Go to a randomly assigned street corner and at a random time and ask *n* people if they own a car\n",
    "\n",
    "Which strikes you as better?\n",
    "\n",
    "What do we want our sample to look like?\n",
    "\n",
    "In particular, what relationship do we want between the sample and the population? What steps can we take to improve our odds of success in achieving this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population vs. Sample Terminology\n",
    "\n",
    "Characteristics of populations are called **parameters**\n",
    "\n",
    "Characteristics of a sample are called **statistics**\n",
    "\n",
    "A sample statistic is a **point estimate** of the population parameter\n",
    "\n",
    "![imgsample](./img/sample_stats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simulation to Reinforce Our Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a population of systolic blood pressure of adult males in Chicago, assuming a mean of 114 mmHg with a standard deviation of 11 mmHg.  We will also assume the adult male population to be 1.5 million. \n",
    "\n",
    "It is impossible to measure the systolic blood pressure of every man in Chicago, but let's assume multiple investigations have led to the conclusion the the mean and std of this population is 114 and 11, respecively. These are therefore estimators of the population parameter.\n",
    "\n",
    "$\\Large\\hat\\mu = 114$  \n",
    "$\\Large\\hat\\sigma = 11$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = int(1.5*10**6)\n",
    "\n",
    "# Use numpy to generate a normal distribution of the \n",
    "sys_pop = np.random.normal(loc=114, scale=11, size=pop)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.kdeplot(sys_pop, ax=ax, shade=True)\n",
    "ax.set_title('Distribution of Adult Male Systolic Blood Pressure')\n",
    "ax.set_xlabel('Systolic BP');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then imagine we develop an effective manner of random sampling, and simulate with numpy. Our sample size is 40 people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 40\n",
    "sample = np.random.choice(sys_pop, sample_size)\n",
    "\n",
    "# We can look at the distribution of the values in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(sample, ax=ax, bins=15)\n",
    "ax.set_title('Sample Distribution of Systolic BP Measurements');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the sample statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sample mean: {sample.mean()}')\n",
    "print(f'Sample standard deviation: {sample.std()}')\n",
    "print(f'Sample median: {np.median(sample)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we repeated this process, taking samples of the population repeatedly, we would get an array of sample statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1000\n",
    "sample_size = 50\n",
    "sample_stats = []\n",
    "\n",
    "for _ in range(number_of_samples):\n",
    "    sample = np.random.choice(sys_pop, sample_size)\n",
    "    # collect the mean of each of the 1000 samples in sample stats\n",
    "    sample_stats.append(sample.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of sample stats represents our __sampling distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(sorted(sample_stats), bins=20)\n",
    "ax.set_title('Sampling Distribution\\n of Systolic BP')\n",
    "ax.set_xlabel(\"Systolic Blood Pressure\")\n",
    "ax.set_ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting property of this sampling distribution:\n",
    "    \n",
    "As we continue to sample, the mean of the sampling distribution gets closer and closer to the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard Error of the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error of the mean is the standard deviation of the sampling distribution.\n",
    "The issue is that a sample is not an exact replica of the population. We need to account for that fact in order to make our estimate of the $\\mu$ value possible. Let's break it down:\n",
    "\n",
    "**Population sigma** <br/>\n",
    "\n",
    "$\\large\\sigma _{x} = \\frac{\\sigma }{\\sqrt{n}}$\n",
    "\n",
    "* $ \\sigma _{x}$ = standard error of $\\bar{x} $\n",
    "* $ \\sigma $ = standard deviation of population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What if we do not know the population sigma?**<br>\n",
    "If we do not know the population standard deviation, we can approximate it by using the sample standard deviation.\n",
    "\n",
    "$\\large\\sigma _{x} â‰ˆ \\frac{s}{\\sqrt{n}}$\n",
    "\n",
    "* s = sample standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sample size impact on standard error of mean**<br>\n",
    "\n",
    "How should sample size influence standard error of the mean?\n",
    "\n",
    "It will get *smaller* as sample size *increases*\n",
    "\n",
    "![error](./img/diminishing_error.png)  \n",
    "Important implication: The Standard Error of the mean remains the same as long as the population standard deviation is known and sample size remains the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error(distribution, largest_sample_size, population_std=None):\n",
    "    \n",
    "    '''\n",
    "    Calculate the standard errors for a range of sample sizes\n",
    "    to demonstrate how standard error decreases when sample \n",
    "    size increases.\n",
    "    '''\n",
    " \n",
    "    std_errors = {}\n",
    "    \n",
    "    for sample_size in range(50, largest_sample_size+1):\n",
    "        sample = np.random.choice(distribution, size=sample_size, replace=True)\n",
    "        # Standard error with sample distribution standard deviation \n",
    "        # in place of population\n",
    "        if population_std == None:\n",
    "            std_err = np.std(sample)/np.sqrt(sample_size)\n",
    "            std_errors[sample_size] = std_err\n",
    "        \n",
    "        else:\n",
    "            std_err = population_std/np.sqrt(sample_size)\n",
    "            std_errors[sample_size] = std_err\n",
    "        \n",
    "    return std_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_errors = standard_error(sys_pop, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(list(std_errors.keys()), list(std_errors.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_errors = standard_error(sys_pop, 1000, population_std=114)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(list(std_errors.keys()), list(std_errors.values()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we take repeated samples of a population, the sampling distribution of sample means will approximate to a normal distribution, no matter the underlying distribution!\n",
    "\n",
    "## $E(\\bar{x_{n}}) = \\mu$\n",
    "\n",
    "as n --> \"large\"\n",
    "\n",
    "[good D3 example](https://seeing-theory.brown.edu/probability-distributions/index.html)\n",
    "\n",
    "[good video demonstration](https://www.youtube.com/watch?v=jvoxEYmQHNM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at an example taken from the ubiquitous Iris dataset. This histogram represents the distributions of sepal length:\n",
    "\n",
    "\n",
    "![probgif](./img/probability-basics.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tentotheminus9/central-limit-theorem-animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see in hypothesis testing, pairing this theorem with the Empirical rule will be very powerful.\n",
    "\n",
    "![empirical](img/empirical_rule.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that any sampling distribtion, no matter the underlying population distribution, will approach normality, we will be able to judge, given the empirical rule, how rare a given sample statistic is.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bike Example\n",
    "Capital bike share is trying to figure out their pricing for members versus non-members. The first step in their analysis is to see if members vs non-members ride for different amounts of time per ride.\n",
    "\n",
    "Let's head over [here](https://s3.amazonaws.com/capitalbikeshare-data/index.html) for some DC bike data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/gdamico/Downloads/202101-capitalbikeshare-tripdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the shape of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duration'] = pd.to_datetime(df['ended_at']) - pd.to_datetime(df['started_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duration'] = df['Duration'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(10, 10))\n",
    "ax[0].hist(df.Duration)\n",
    "sns.kdeplot(df.Duration, ax=ax[1])\n",
    "sns.boxplot(df.Duration, ax=ax[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is difficult to see because of the outliers. Let's remove some to get a better sense of the shape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Duration'] < 0].shape[0]\n",
    "\n",
    "df = df[df['Duration'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_no_outliers = df[np.abs(stats.zscore(df.Duration)) < 3]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.distplot(pop_no_outliers.Duration);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "member_df = df[df['member_casual'] == 'member']\n",
    "casual_df = df[df['member_casual'] == 'casual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(member_df['Duration']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(member_df.shape)\n",
    "sum(abs(stats.zscore(member_df.Duration)) > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_df_nooutliers = member_df[np.abs(stats.zscore(member_df.Duration)) < 3]\n",
    "member_df_nooutliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(member_df_nooutliers.Duration, bins=50, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(casual_df.Duration);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casual_df_nooutliers = casual_df[np.abs(stats.zscore(casual_df.Duration)) < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(casual_df_nooutliers.Duration, bins=20, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(member_df_nooutliers.Duration, bins=20, ax=ax, color='blue')\n",
    "sns.distplot(casual_df_nooutliers.Duration, bins=20, ax=ax, color='green');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Get population statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's treat the whole dataset as our population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pop_mean = df.Duration.mean()\n",
    "pop_std = df.Duration.std()\n",
    "print(f'pop_mean is {pop_mean} \\npop_std is {pop_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def one_sample_mean(population):\n",
    "    sample = np.random.choice(population, size=200, replace=True)\n",
    "    return sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample_mean(df.Duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When we take multiple samples from the distribution,and plot the means of each sample, the shape of the curve shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d = [one_sample_mean(df.Duration) for i in range(1000)]\n",
    "plt.hist(d, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def central_limit_theorem_plotter(distribution, sample_size, num_samples, color='blue'):\n",
    "    sample_means = np.zeros(num_samples)\n",
    "    for idx, num in enumerate(range(num_samples)):\n",
    "        sample = np.random.choice(distribution, size=sample_size, replace=True)\n",
    "        sample_means[idx] = sample.mean()\n",
    "    sns.distplot(sample_means, bins=80, kde=True,  color=color)\n",
    "    title = f'Sample Distribution n = {sample_size} and number of samples = {num_samples},\\\n",
    "    std error = {pop_std / num_samples}'\n",
    "    print(f'mean = {sample_means.mean()}')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of samples drives the shape of the curve more than the sample size itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "central_limit_theorem_plotter(df.Duration, 1000, 500);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger sample size, Fewer samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "central_limit_theorem_plotter(df.Duration, 5000, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What happens as we increase the sample size?\n",
    "* How does the height of the distribution change? Why does it change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_limit_theorem_plotter(member_df.Duration, 1000, 500, 'blue')\n",
    "central_limit_theorem_plotter(casual_df.Duration, 1000, 500, 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
