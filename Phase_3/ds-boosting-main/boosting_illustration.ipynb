{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Illustration of Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0, 20, 201)\n",
    "y = np.sin(X)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 \n",
    "\n",
    "Here, all we are doing is using an average of our values as a model of our data. Note that the \"actual function\" of our data is a sine curve. We are going to try to approximate that by way of gradient boosting and a decision tree regressor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y)\n",
    "f0 = y.mean()\n",
    "ax.hlines(f0, 0, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OK, so we have our extremely basic, extremely inaccurate model. Let's go ahead and build off of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals\n",
    "\n",
    "e0 = y - f0\n",
    "e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Plotting residuals\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, e0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: fitting a \"stump\" to the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = X.reshape(-1, 1)\n",
    "f1 = DecisionTreeRegressor(max_depth=1)\n",
    "\n",
    "f1.fit(data, e0)\n",
    "ensemble_preds_1 = f1.predict(data) + f0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y)\n",
    "ax.scatter(X, ensemble_preds_1,\n",
    "          c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DecisionTreeRegressor is minimizing\n",
    "# mean squared error. Since we're only\n",
    "# splitting once, we're simply predicting\n",
    "# the mean of each of the two groups formed\n",
    "# by the split.\n",
    "\n",
    "mses = []\n",
    "for j in range(1, 63):\n",
    "    mse = sum((e0[:j] - e0[:j].mean())**2)\n",
    "    mse += sum((e0[j:] - e0[j:].mean())**2)\n",
    "    mses.append(mse)\n",
    "mses.index(min(mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(f1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e0[:29].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e0[29:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: fitting another \"stump\" to the residuals of the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = y - (f0 + f1.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = DecisionTreeRegressor(max_depth=1)\n",
    "f2.fit(data, e1)\n",
    "ensemble_preds_2 = f1.predict(data) + f2.predict(data) + f0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, e1)\n",
    "ax.scatter(X, ensemble_preds_2)\n",
    "plt.title('fitting to residuals (y - (f0(x) + f1(x)))');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y)\n",
    "ax.scatter(X, ensemble_preds_2,\n",
    "          c='r')\n",
    "plt.title('Model v. our data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting yet another \"stump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = y - (f2.predict(data) + f1.predict(data) + f0)\n",
    "f3 = DecisionTreeRegressor(max_depth=1)\n",
    "f3.fit(data, e2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, e2)\n",
    "ensemble_preds_3 = f3.predict(data) + f2.predict(data) + f1.predict(data) + f0\n",
    "ax.scatter(X, ensemble_preds_3)\n",
    "plt.title('fitting to residuals (y - (f0(x) + f1(x) + f2(x)))');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, np.sin(X))\n",
    "ax.scatter(X, ensemble_preds_3,\n",
    "          c='r')\n",
    "plt.title('Model v. our data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = y - (f3.predict(data) + f2.predict(data) + f1.predict(data) + f0)\n",
    "f4 = DecisionTreeRegressor(max_depth=1)\n",
    "f4.fit(data, e3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, e3)\n",
    "ensemble_preds_4 = f4.predict(data) + f3.predict(data) + f2.predict(data)\\\n",
    "    + f1.predict(data) + f0\n",
    "ax.scatter(X, ensemble_preds_4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, np.sin(X))\n",
    "ax.scatter(X, ensemble_preds_4,\n",
    "          c='r')\n",
    "plt.title('Model v. our data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4 = np.sin(X) - (f4.predict(data) + f3.predict(data) + f2.predict(data)\\\n",
    "                  + f1.predict(data) + f0)\n",
    "f5 = DecisionTreeRegressor(max_depth=1)\n",
    "f5.fit(data, e4)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, e4)\n",
    "ensemble_preds_5 = f5.predict(data) + f4.predict(data) + f3.predict(data)\\\n",
    "    + f2.predict(data) + f1.predict(data) + f0\n",
    "ax.scatter(X, ensemble_preds_5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, np.sin(X))\n",
    "ax.scatter(X, ensemble_preds_5,\n",
    "          c='r')\n",
    "plt.title('Model v. our data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a function already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_boosting_algorithm(X, y, n_learners, learner,\n",
    "                              learning_rate, show_each_step=True):\n",
    "    \"\"\"Performs a simple ensemble boosting model \n",
    "    params: show_each_step - if True, will show with each additional learner\"\"\"\n",
    "    f0 = y.mean()\n",
    "    residuals = y - f0\n",
    "    \n",
    "    # This next line fills an array of len(y) with the mean of y.\n",
    "    ensemble_predictions = np.full(len(y), fill_value=f0)\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "    for i in range(n_learners):\n",
    "        residuals = y - ensemble_predictions\n",
    "        f = learner.fit(X.reshape(-1, 1), residuals)\n",
    "        ensemble_predictions = learning_rate * f.predict(X.reshape(-1, 1)) +\\\n",
    "        ensemble_predictions\n",
    "        if show_each_step:\n",
    "            ax.plot(X, y)\n",
    "            ax.scatter(X, ensemble_predictions,\n",
    "                      c='r')\n",
    "            \n",
    "    ax.plot(X, y)\n",
    "    ax.scatter(X, ensemble_predictions,\n",
    "              c='r')\n",
    "            \n",
    "    plt.title('With ' + str(n_learners) + ' learners with a depth of '+\\\n",
    "              str(learner.max_depth) +\\\n",
    "              ' and a learning rate of '+ str(learning_rate))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=1,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.001,\n",
    "                          show_each_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=100,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.01,\n",
    "                          show_each_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=10000,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.001,\n",
    "                          show_each_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=100000,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.01,\n",
    "                          show_each_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=20,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.1,\n",
    "                          show_each_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=60,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.1,\n",
    "                          show_each_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=80,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.1,\n",
    "                          show_each_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=200,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.1,\n",
    "                          show_each_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_boosting_algorithm(X=X,\n",
    "                          y=y,\n",
    "                          n_learners=1000,\n",
    "                          learner=DecisionTreeRegressor(max_depth=1),\n",
    "                          learning_rate=0.01,\n",
    "                          show_each_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
