{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Agenda\" data-toc-modified-id=\"Agenda-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Agenda</a></span></li><li><span><a href=\"#Preparing-Data\" data-toc-modified-id=\"Preparing-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preparing Data</a></span></li><li><span><a href=\"#Fitting-a-Line-to-$Logit(target)$\" data-toc-modified-id=\"Fitting-a-Line-to-$Logit(target)$-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Fitting a Line to $Logit(target)$</a></span><ul class=\"toc-item\"><li><span><a href=\"#sklearn.linear_model.LogisticRegression()\" data-toc-modified-id=\"sklearn.linear_model.LogisticRegression()-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>sklearn.linear_model.LogisticRegression()</code></a></span></li><li><span><a href=\"#.predict()-vs.-.predict_proba()\" data-toc-modified-id=\".predict()-vs.-.predict_proba()-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><code>.predict()</code> vs. <code>.predict_proba()</code></a></span></li><li><span><a href=\"#Cost-Functions-and-Solutions-to-the-Optimization-Problem\" data-toc-modified-id=\"Cost-Functions-and-Solutions-to-the-Optimization-Problem-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Cost Functions and Solutions to the Optimization Problem</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-bad-news:\" data-toc-modified-id=\"The-bad-news:-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>The bad news:</a></span></li><li><span><a href=\"#The-good-news:\" data-toc-modified-id=\"The-good-news:-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>The good news:</a></span></li></ul></li><li><span><a href=\"#Interpreting-Logistic-Regression-Coefficients\" data-toc-modified-id=\"Interpreting-Logistic-Regression-Coefficients-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Interpreting Logistic Regression Coefficients</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-Coefficients-to-Generate-Prediction\" data-toc-modified-id=\"Use-Coefficients-to-Generate-Prediction-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Use Coefficients to Generate Prediction</a></span></li></ul></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exercise</a></span></li><li><span><a href=\"#Level-Up\" data-toc-modified-id=\"Level-Up-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Level Up</a></span><ul class=\"toc-item\"><li><span><a href=\"#More-Generalizations:-Other-Link-Functions,-Other-Models\" data-toc-modified-id=\"More-Generalizations:-Other-Link-Functions,-Other-Models-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>More Generalizations: Other Link Functions, Other Models</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For our modeling steps\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# For demonstrative pruposes\n",
    "from scipy.special import logit, expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "SWBAT:\n",
    "\n",
    "- Explain the form of logistic regression\n",
    "- Explain how to interpret logistic regression coefficients\n",
    "- Use logistic regression to perform a classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type\n",
       "id                                                                        \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1\n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6\n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glass identification dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "col_names = ['id','ri','na','mg','al','si','k','ca','ba','fe','glass_type']\n",
    "glass = pd.read_csv(url, names=col_names, index_col='id')\n",
    "glass.sort_values('al', inplace=True)\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type  \\\n",
       "id                                                                           \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1   \n",
       "\n",
       "     household  \n",
       "id              \n",
       "22           0  \n",
       "185          1  \n",
       "40           0  \n",
       "39           0  \n",
       "51           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types 1, 2, 3 are window glass\n",
    "# types 5, 6, 7 are household glass\n",
    "glass['household'] = glass.glass_type.map({1:0, 2:0, 3:0, 5:1, 6:1, 7:1})\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fitting a Line to $Logit(target)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Nonlinear transformation of a logistic to linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try applying the logit function to our target and then fitting a linear regression to that. Since the model will be trained not on whether the glass is household but rather on *the logit of this label*, it will also make predictions of the logit of that label. But we can simply apply the sigmoid function to the model's output to get its predictions of whether the glass is household.\n",
    "\n",
    "We can't use the target as is, because the logit of 1 is $\\infty$ and the logit of 0 is $-\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass['household'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-inf,  inf])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit(glass['household']).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we'll make a small adjustment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">approximation of infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_approx = np.where(glass['household'] == 0, 1e-9, 1-1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_to_logit = LinearRegression()\n",
    "\n",
    "X = glass[['al']]\n",
    "y = logit(target_approx)\n",
    "\n",
    "line_to_logit.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">expit is the inverse of the logit function It is bringing the infities to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "final_preds = expit(line_to_logit.predict(X))\n",
    "ax.scatter(X, glass['household'])\n",
    "ax.plot(X, final_preds, 'm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The threshold switches at 2. The ones that are not in the line are the incorrect ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `sklearn.linear_model.LogisticRegression()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In general, we should always scale our data when using this class. Scaling is always important for models that include regularization, and scikit-learn's `LogisticRegression()` objects have regularization by default.\n",
    "\n",
    "Here we've forgone the scaling since we only have a single predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit a logistic regression model and store the class predictions\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "logreg.fit(X, y)\n",
    "glass['household_pred_class'] = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "      <th>household_pred_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>73.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.51321</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.02</td>\n",
       "      <td>70.70</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.51316</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>70.48</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.51514</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.50</td>\n",
       "      <td>69.89</td>\n",
       "      <td>1.68</td>\n",
       "      <td>5.87</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca    ba    fe  glass_type  \\\n",
       "id                                                                            \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.00  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.00  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.00  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.00  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.00  0.16           1   \n",
       "..       ...    ...   ...   ...    ...   ...    ...   ...   ...         ...   \n",
       "193  1.51623  14.20  0.00  2.79  73.46  0.04   9.04  0.40  0.09           7   \n",
       "210  1.51623  14.14  0.00  2.88  72.61  0.08   9.18  1.06  0.00           7   \n",
       "173  1.51321  13.00  0.00  3.02  70.70  6.21   6.93  0.00  0.00           5   \n",
       "172  1.51316  13.02  0.00  3.04  70.48  6.21   6.96  0.00  0.00           5   \n",
       "164  1.51514  14.01  2.68  3.50  69.89  1.68   5.87  2.20  0.00           5   \n",
       "\n",
       "     household  household_pred_class  \n",
       "id                                    \n",
       "22           0                     0  \n",
       "185          1                     0  \n",
       "40           0                     0  \n",
       "39           0                     0  \n",
       "51           0                     0  \n",
       "..         ...                   ...  \n",
       "193          1                     1  \n",
       "210          1                     1  \n",
       "173          1                     1  \n",
       "172          1                     1  \n",
       "164          1                     1  \n",
       "\n",
       "[214 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass #The last column is the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the class predictions\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(glass.al, glass.household)\n",
    "ax.plot(glass.al, glass.household_pred_class, color='red')\n",
    "ax.set_xlabel('al')\n",
    "ax.set_ylabel('household');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `.predict()` vs. `.predict_proba()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's checkout some specific examples to make predictions with. We'll use both `predict()` and `predict_proba()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "22     0.29\n",
       "185    0.34\n",
       "40     0.47\n",
       "39     0.47\n",
       "51     0.51\n",
       "       ... \n",
       "193    2.79\n",
       "210    2.88\n",
       "173    3.02\n",
       "172    3.04\n",
       "164    3.50\n",
       "Name: al, Length: 214, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass.al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "\n",
      "\n",
      "[0.9939759 0.0060241]\n",
      "[0.99296771 0.00703229]\n",
      "[0.00743731 0.99256269]\n"
     ]
    }
   ],
   "source": [
    "# examine some example predictions\n",
    "\n",
    "print(logreg.predict(glass['al'][22].reshape(1, -1)))\n",
    "print(logreg.predict(glass['al'][185].reshape(1, -1)))\n",
    "print(logreg.predict(glass['al'][164].reshape(1, -1)))\n",
    "print('\\n')\n",
    "print(logreg.predict_proba(glass['al'][22].reshape(1, -1))[0])\n",
    "print(logreg.predict_proba(glass['al'][185].reshape(1, -1))[0])\n",
    "print(logreg.predict_proba(glass['al'][164].reshape(1, -1))[0])\n",
    "first_row = glass['al'][22].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilites of class 1\n",
    "glass['household_pred_prob'] = logreg.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the predicted probabilities\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(glass.al, glass.household)\n",
    "ax.plot(glass.al, glass.household_pred_prob, color='red')\n",
    "ax.set_xlabel('al')\n",
    "ax.set_ylabel('household');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">as we get further to the right or left we can be more certain of what the classification is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first column indicates the predicted probability of **class 0**, and the second column indicates the predicted probability of **class 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36150680872607704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(glass.household, logreg.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above is a pretty good score. A baseline classifier that is fit on data with equal numbers of data points in the two target classes should be right about 50% of the time, and the log loss for such a classifier would be $-ln(0.5) = 0.693$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Cost Functions and Solutions to the Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unlike the least-squares problem for linear regression, no one has yet found a closed-form solution to the optimization problem presented by logistic regression. But even if one exists, the computation would no doubt be so complex that we'd be better off using some sort of approximation method instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But there's still a problem.\n",
    "\n",
    "Recall the cost function for linear regression: <br/><br/>\n",
    "$SSE = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i(y_i - (\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in}))^2$.\n",
    "\n",
    "This function, $SSE(\\vec{\\beta})$, is convex.\n",
    "\n",
    "If we plug in our new logistic equation for $\\hat{y}$, we get: <br/><br/>\n",
    "$SSE_{log} = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i\\left(y_i - \\left(\\frac{1}{1+e^{-(\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in})}}\\right)\\right)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The bad news:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*This* function, $SSE_{log}(\\vec{\\beta})$, is [**not** convex](https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c).\n",
    "\n",
    "That means that, if we tried to use gradient descent or some other approximation method that looks for the minimum of this function, we could easily find a local rather than a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note that the scikit-learn class *expects the user to specify the solver* to be used in calculating the coefficients. The default solver, [lbfgs](https://en.wikipedia.org/wiki/Limited-memory_BFGS), works well for many applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The good news:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Log loss is better for gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">more mistakes value is larger less is smaller the better the function the smaller the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use **log-loss** instead:\n",
    "\n",
    "$\\mathcal{L}(\\vec{y}, \\hat{\\vec{y}}) = -\\frac{1}{N}\\Sigma^N_{i=1}\\left(y_iln(\\hat{y}_i)+(1-y_i)ln(1-\\hat{y}_i)\\right)$,\n",
    "\n",
    "where $\\hat{y}_i$ is the probability that $(x_{i1}, ... , x_{in})$ belongs to **class 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**More resources on the log-loss function**:\n",
    "\n",
    "https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11\n",
    "\n",
    "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a\n",
    "\n",
    "http://wiki.fast.ai/index.php/Log_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Interpreting Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">factor of e ^ k relative to the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.11517927]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How do we interpret the coefficients of a logistic regression? For a linear regression, the situaton was like this:\n",
    "\n",
    "- Linear Regression: We construct the best-fit line and get a set of coefficients. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change in $y$.\n",
    "\n",
    "- Logistic Regression: We find the coefficients of the best-fit line by some approximation method. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change (not in $y$ but) in $ln\\left(\\frac{y}{1-y}\\right)$.\n",
    "\n",
    "We have:\n",
    "\n",
    "$\\ln\\left(\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}\\right) = \\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k$.\n",
    "\n",
    "Exponentiating both sides:\n",
    "\n",
    "$\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)} = e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k}$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right)}\\cdot e^k$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^k\\cdot\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}$\n",
    "\n",
    "That is, the odds ratio at $x_1+1$ has increased by a factor of $e^k$ relative to the odds ratio at $x_1$.\n",
    "\n",
    "For more on interpretation, see [this page](https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/binary-logistic-regression/interpret-the-results/all-statistics-and-graphs/coefficients/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.00934605])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the intercept\n",
    "\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** For an 'al' value of 0, the log-odds of 'household' is -6.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00244968])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to probability\n",
    "\n",
    "logodds = logreg.intercept_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The coefficient reversed tells you how much the prob will increase based on the x value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('al', 3.1151792681570165)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the coefficient for al\n",
    "\n",
    "list(zip(feature_cols, logreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** A 1 unit increase in 'al' is associated with a 3.12 unit increase in the log-odds of 'household'.\n",
    "\n",
    "Let's verify this as we change the aluminum content from 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94755733, 0.05244267]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=1\n",
    "\n",
    "pred_al1 = logreg.predict_proba([[1]])\n",
    "pred_al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Odds ratio for al=1\n",
    "\n",
    "odds_al1 = pred_al1[0][1] / pred_al1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4449707, 0.5550293]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=2\n",
    "pred_al2 = logreg.predict_proba([[2]])\n",
    "pred_al2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Odds ratio for al=2\n",
    "\n",
    "odds_al2 = pred_al2[0][1] / pred_al2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2473390003597826\n",
      "1.2473390003597828\n"
     ]
    }
   ],
   "source": [
    "print((np.exp(logreg.coef_[0]) * odds_al1)[0])\n",
    "print(odds_al2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Interpretting coefficients: https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/binary-logistic-regression/interpret-the-results/all-statistics-and-graphs/coefficients/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Use Coefficients to Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute predicted log-odds for al=2 using the equation\n",
    "\n",
    "logodds = logreg.intercept_ + logreg.coef_[0] * 2\n",
    "logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert log-odds to odds\n",
    "\n",
    "odds = np.exp(logodds)\n",
    "odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert odds to probability\n",
    "\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute predicted probability for al=2 using the predict_proba method\n",
    "\n",
    "logreg.predict_proba(np.array([2]).reshape(1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data below into train and test, and then convert the y-values (`geysers.kind`) into 1's and 0's. Then use `sklearn` to build a logistic regression model of whether Old Faithful's eruption wait time is long or short, based on the duration of the eruption. Finally, find the points in the test set where the model's prediction differs from the true y-value. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "geysers = sns.load_dataset('geyser', **{'usecols': ['duration', 'kind']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.600</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.800</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.283</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.533</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   kind\n",
       "0     3.600   long\n",
       "1     1.800  short\n",
       "2     3.333   long\n",
       "3     2.283  short\n",
       "4     4.533   long"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>kind</th>\n",
       "      <th>erup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.600</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.800</td>\n",
       "      <td>short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.283</td>\n",
       "      <td>short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.533</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   kind  erup\n",
       "0     3.600   long     1\n",
       "1     1.800  short     0\n",
       "2     3.333   long     1\n",
       "3     2.283  short     0\n",
       "4     4.533   long     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers['erup'] = np.where(geysers['kind'] =='long', 1, 0)\n",
    "geysers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X = geysers.duration\n",
    "y = geysers.erup\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize\n",
    "X_train_norm = normalize(X_train.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define & Fit Model (with train)\n",
    "model = LogisticRegression()\n",
    "#Fit\n",
    "model.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631336405529954"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     137\n",
       "False     80\n",
       "Name: erup, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = (y_train == model.predict(X_train_norm))\n",
    "residuals\n",
    "pd.Series(residuals).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(normalize(X_test.to_numpy().reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = (y_test == yhat)\n",
    "pd.Series(residuals).value_counts()\n",
    "\n",
    "35/55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## More Generalizations: Other Link Functions, Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Logistic regression's link function is the logit function, but different sorts of models use different link functions.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function) has a nice table of generalized linear model types and their associated link functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
