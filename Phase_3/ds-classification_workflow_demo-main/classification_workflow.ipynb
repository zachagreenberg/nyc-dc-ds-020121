{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Walkthrough\n",
    "\n",
    "## Agenda\n",
    "\n",
    "The goal here is to illustrate a possible workflow for classification modeling with `sklearn`'s `LogisticRegression` model.\n",
    "\n",
    "SWBAT:\n",
    "\n",
    "- formulate and implement an iterative modeling workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# plot_confusion_matrix is a handy visual tool, added in the latest version of scikit-learn\n",
    "# if you are running an older version, comment out this line and just use confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Steps\n",
    "\n",
    "1. Build a model based on the [Titanic dataset](https://www.kaggle.com/c/titanic/data) that predicts whether a given person survived or not\n",
    "2. Evaluate the performance of the model\n",
    "3. Make changes in an attempt to improve the model\n",
    "4. Demonstrate whether an improvement was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "This dataset has the following columns:\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| -------- | ---------- | --- |\n",
    "| survival | Survival | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| Age | Age in years | |\n",
    "| sibsp | # of siblings / spouses aboard the Titanic | |\n",
    "| parch | # of parents / children aboard the Titanic | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passenger fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Understanding and Preparation\n",
    "\n",
    "Open up the file, get everything into `X` features and `y` target variables, divided into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age data is missing for about 1 in 9 rows in our dataset.  For now, let's just exclude it, plus the non-numeric columns, and `PassengerId`, which doesn't seem like a real feature, but rather just an artifact of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pclass are numbers but it's not clear that the difference between 1st and 2nd is the\n",
    "# same as the difference between 2nd and 3rd\n",
    "numeric_columns = [\"Survived\", \"SibSp\", \"Parch\", \"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[numeric_columns]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df[numeric_columns]\n",
    "X = numeric_df.drop(\"Survived\", axis=1)\n",
    "y = numeric_df[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Let's start with a completely \"dummy\" model, that will always choose the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should expect all predictions to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just grabbing the first 50 to save space\n",
    "dummy_model.predict(X_train)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dummy_model, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the mean accuracy is a little over 62% if we always guess the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Dummy Model\")\n",
    "\n",
    "plot_confusion_matrix(dummy_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the numbers (this should work even with older scikit-learn)\n",
    "confusion_matrix(y_train, dummy_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretty lopsided confusion matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling, Part 2\n",
    "\n",
    "Let's use a logistic regression and compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_logreg_model = LogisticRegression(random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_logreg_model.predict(X_train)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixture of 1s and 0s this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation, Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(simple_logreg_model, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the mean accuracy is closer to 70% if the model is actually taking in information from the features instead of always guessing the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with Numeric Features Only\")\n",
    "\n",
    "plot_confusion_matrix(simple_logreg_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, simple_logreg_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in general we are not labeling many of the \"not survived\" passengers as \"survived\", but for \"survived\" passengers we're getting it wrong most of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation, Part 2\n",
    "\n",
    "Maybe there is some useful information in the features we are not using yet.  Let's go wild and add all of them!\n",
    "\n",
    "Note: you can and should add features incrementally in a \"real\" modeling context.  The engineering effort of encoding the variables can be non-trivial!  But here let's assume that it's not too much work to encode all of them.\n",
    "\n",
    "Start with a new train-test split that contains all of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Let's be extra cautious and make a separate column to indicate whether there originally was a missing value.\n",
    "\n",
    "In our training data there are only missing values for a couple of the columns, but we can't be sure about where the test set will be missing data.\n",
    "\n",
    "The `MissingIndicator` from `sklearn` will mark the missing values in an input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_demo = MissingIndicator()\n",
    "\n",
    "indicator_demo.fit(X_train)\n",
    "\n",
    "indicator_demo.features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_demo.transform(X_train)[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:5, [3, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = MissingIndicator(features=\"all\")\n",
    "indicator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_indicator_columns(X, indicator):\n",
    "    \"\"\"\n",
    "    Helper function for transforming features\n",
    "    \n",
    "    For every feature in X, create another feature indicating whether that feature\n",
    "    is missing. (This doubles the number of columns in X.)\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a 2D array of True and False values indicating whether a given feature\n",
    "    # is missing for that row\n",
    "    missing_array_bool = indicator.transform(X)\n",
    "    \n",
    "    # transform into 1 and 0 for modeling\n",
    "    missing_array_int = missing_array_bool.astype(int)\n",
    "    \n",
    "    # helpful for readability but not needed for modeling\n",
    "    missing_column_names = [col + \"_missing\" for col in X.columns]\n",
    "    \n",
    "    # convert to df so it we can concat with X\n",
    "    missing_df = pd.DataFrame(missing_array_int, columns=missing_column_names, index=X.index)\n",
    "    \n",
    "    return pd.concat([X, missing_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = add_missing_indicator_columns(X=X_train, indicator=indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've specified which values were originally missing, let's fill in those missing values.  This takes two separate imputers because we want to use the mean for numeric data and the majority class for categorical data.\n",
    "\n",
    "The `SimpleImputer` class fills in the mean value by default, so we'll have to override that for the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_names = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "categorical_feature_names = [\"Pclass\", \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "X_train_numeric = X_train[numeric_feature_names]\n",
    "X_train_categorical = X_train[categorical_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer()\n",
    "numeric_imputer.fit(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "categorical_imputer.fit(X_train_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build a function here to minimize our work of imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(X, imputer):\n",
    "    \"\"\"\n",
    "    Given a DataFrame and an imputer, use the imputer to fill in all\n",
    "    missing values in the DataFrame\n",
    "    \"\"\"\n",
    "    imputed_array = imputer.transform(X)\n",
    "    imputed_df = pd.DataFrame(imputed_array, columns=X.columns, index=X.index)\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = impute_missing_values(X_train_numeric, numeric_imputer)\n",
    "X_train_categorical = impute_missing_values(X_train_categorical, categorical_imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check to make sure that all of the missing values are gone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed = pd.concat([X_train_numeric, X_train_categorical], axis=1)\n",
    "X_train_imputed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all of the old columns from X_train, then concat the new imputed ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(numeric_feature_names + categorical_feature_names, axis=1)\n",
    "X_train = pd.concat([X_train_imputed, X_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Now that there are no missing values, convert all of the categorical features into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature_train(X_train, feature_name):\n",
    "    \"\"\"\n",
    "    Helper function for transforming training data.  It takes in the full X dataframe and\n",
    "    feature name, makes a one-hot encoder, and returns the encoder as well as the dataframe\n",
    "    with that feature transformed into multiple columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # make a one-hot encoder and fit it to the training data\n",
    "    ohe = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "    single_feature_df = X_train[[feature_name]]\n",
    "    ohe.fit(single_feature_df)\n",
    "    \n",
    "    # call helper function that actually encodes the feature and concats it\n",
    "    X_train = encode_and_concat_feature(X_train, feature_name, ohe)\n",
    "    \n",
    "    return ohe, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature(X, feature_name, ohe):\n",
    "    \"\"\"\n",
    "    Helper function for transforming a feature into multiple columns of 1s and 0s. Used\n",
    "    in both training and testing steps.  Takes in the full X dataframe, feature name, \n",
    "    and encoder, and returns the dataframe with that feature transformed into multiple\n",
    "    columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # create new one-hot encoded df based on the feature\n",
    "    single_feature_df = X[[feature_name]]\n",
    "    feature_array = ohe.transform(single_feature_df).toarray()\n",
    "    ohe_df = pd.DataFrame(feature_array, columns=ohe.categories_[0], index=X.index)\n",
    "    \n",
    "    # drop the old feature from X and concat the new one-hot encoded df\n",
    "    X = X.drop(feature_name, axis=1)\n",
    "    X = pd.concat([X, ohe_df], axis=1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "\n",
    "for categorical_feature in categorical_feature_names:\n",
    "    ohe, X_train = encode_and_concat_feature_train(X_train, categorical_feature)\n",
    "    encoders[categorical_feature] = ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is...a ridiculous number of columns.  How did we end up with more columns than rows?\n",
    "\n",
    "(Answer: each unique name and ticket number is now its own column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling, Part 3\n",
    "\n",
    "Let's run a logistic regression on our ridiculous number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021)\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened there?  This solver had no problem before.\n",
    "\n",
    "Answer: it wasn't able to find the minimum with this number of steps in gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjustments\n",
    "\n",
    "Let's try a couple of stopgap measures to get the model to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_more_iterations = LogisticRegression(random_state=2021, max_iter=1000)\n",
    "logreg_model_more_iterations.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More regularization\n",
    "\n",
    "Remember that the `C` parameter is the inverse of the regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_more_regularization = LogisticRegression(random_state=2021, C=0.01)\n",
    "logreg_model_more_regularization.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_higher_tolerance = LogisticRegression(random_state=2021, tol=50)\n",
    "logreg_model_higher_tolerance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation, Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 6))\n",
    "\n",
    "axes[0].set_title(\"More Iterations\")\n",
    "axes[1].set_title(\"More Regularization\")\n",
    "axes[2].set_title(\"Higher Tolerance\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model_more_iterations, X_train, y_train,\n",
    "                      ax=axes[0], cmap=\"plasma\")\n",
    "plot_confusion_matrix(logreg_model_more_regularization, X_train, y_train,\n",
    "                      ax=axes[1], cmap=\"plasma\")\n",
    "plot_confusion_matrix(logreg_model_higher_tolerance, X_train, y_train,\n",
    "                      ax=axes[2], cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(logreg_model_more_iterations, X_train, y_train, cv=3))\n",
    "print(cross_val_score(logreg_model_more_regularization, X_train, y_train, cv=3))\n",
    "print(cross_val_score(logreg_model_higher_tolerance, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_roc_curve(logreg_model_more_iterations, X_train, y_train, \n",
    "               name='logreg_model_more_iterations', ax=ax)\n",
    "plot_roc_curve(logreg_model_more_regularization, X_train, y_train, \n",
    "               name='logreg_model_more_regularization', ax=ax)\n",
    "plot_roc_curve(logreg_model_higher_tolerance, X_train, y_train, \n",
    "               name='logreg_model_higher_tolerance', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation, Part 3\n",
    "\n",
    "Let's scale all of the features, so the model isn't overly penalizing age and fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values(X, scaler):\n",
    "    \"\"\"\n",
    "    Given a DataFrame and a fitted scaler, use the scaler to scale all of the features\n",
    "    \"\"\"\n",
    "    scaled_array = scaler.transform(X)\n",
    "    scaled_df = pd.DataFrame(scaled_array, columns=X.columns, index=X.index)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scale_values(X_train, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling, Part 4\n",
    "\n",
    "Now that the data is scaled, let's see if we can fit the model without tweaking any hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021)\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation, Part 4\n",
    "\n",
    "Now that we are able to run a logistic regression with default hyperparameters, let's see how that performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with All Features, Scaled\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_cross_val_score = cross_val_score(logreg_model, X_train, y_train, cv=3)\n",
    "all_features_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(logreg_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect on the training data, high 70% range on the test data ... this might be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(X_train.columns, logreg_model.coef_[0])),\n",
    "       key=lambda x: abs(x[1]), reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Adjustment\n",
    "\n",
    "\n",
    "### Different Regularization Strengths\n",
    "\n",
    "Let's try out some different regularization penalties to see if we can improve the test data score a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, C=0.1)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it doesn't make a difference.\n",
    "\n",
    "Try a little less regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, C=0.5)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same or worse.\n",
    "\n",
    "Try a little more regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, C=0.05)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also worse.  It looks like the default C value is pretty optimal for this solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Solvers\n",
    "\n",
    "Let's try also some other solvers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, solver=\"liblinear\")\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little slower, but no major difference in the scores.  Let's try adding some more regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, solver=\"liblinear\", C=0.01)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting better.  Try a different type of penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, solver=\"liblinear\", penalty=\"l1\")\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better average here.  Try adding some more regularization with L1 penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, solver=\"liblinear\", penalty=\"l1\", C=0.01)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, the default regularization strength seems pretty good.  Double-check the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2021, solver=\"liblinear\", penalty=\"l1\")\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with All Features (Scaled, Hyperparameters Tuned)\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SelectFromModel`\n",
    "\n",
    "The last model is probably overfitting. We might try thinning out the number of features by eliminating the ones with small modeling coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectFromModel(logreg_model)\n",
    "\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the default threshold here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = selector.threshold_\n",
    "thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sense of which features will be eliminated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = selector.estimator_.coef_\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs[coefs > thresh].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(X_train.columns, selector.get_support()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_features(X, selector):\n",
    "    \"\"\"\n",
    "    Given a DataFrame and a selector, use the selector to choose\n",
    "    the most important columns\n",
    "    \"\"\"\n",
    "    imps = dict(zip(X.columns, selector.get_support()))\n",
    "    selected_array = selector.transform(X)\n",
    "    selected_df = pd.DataFrame(selected_array,\n",
    "                               columns=[col for col in X.columns if imps[col]],\n",
    "                               index=X.index)\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = select_important_features(X=X_train, selector=selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_sel = LogisticRegression(random_state=2021, solver=\"liblinear\", penalty=\"l1\")\n",
    "\n",
    "logreg_sel.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(logreg_sel, X_train_selected, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably still overfitting, but let's call this our final model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation\n",
    "\n",
    "Now that we have a final model, run X_test through all of the preprocessing steps so we can evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_no_transformations = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing indicators\n",
    "X_test_mi = add_missing_indicator_columns(X_test_no_transformations, indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out values for imputation\n",
    "X_test_numeric = X_test_mi[numeric_feature_names]\n",
    "X_test_categorical = X_test_mi[categorical_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "X_test_numeric = impute_missing_values(X_test_numeric, numeric_imputer)\n",
    "X_test_categorical = impute_missing_values(X_test_categorical, categorical_imputer)\n",
    "X_test_imputed = pd.concat([X_test_numeric, X_test_categorical], axis=1)\n",
    "X_test_new = X_test_mi.drop(numeric_feature_names + categorical_feature_names, axis=1)\n",
    "X_test_final = pd.concat([X_test_imputed, X_test_new], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categorical data\n",
    "for categorical_feature in categorical_feature_names:\n",
    "    X_test_final = encode_and_concat_feature(X_test_final,\n",
    "                                       categorical_feature, encoders[categorical_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values\n",
    "X_test_scaled = scale_values(X_test_final, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "X_test_selected = select_important_features(X_test_scaled, selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with the relevant hyperparameters, fit, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(random_state=2021, solver=\"liblinear\", penalty=\"l1\")\n",
    "final_model.fit(X_train_selected, y_train)\n",
    "\n",
    "final_model.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the past models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a way to categorize our different models\n",
    "model_candidates = [\n",
    "    {\n",
    "        'name':'logreg_model_more_iterations'\n",
    "        ,'model':logreg_model_more_iterations\n",
    "        ,'X_test':X_test_final\n",
    "        ,'y_test':y_test\n",
    "    },\n",
    "    {\n",
    "        'name':'logreg_model_more_regularization'\n",
    "        ,'model':logreg_model_more_regularization\n",
    "        ,'X_test':X_test_final\n",
    "        ,'y_test':y_test\n",
    "    },\n",
    "    {\n",
    "        'name':'logreg_model_higher_tolerance'\n",
    "        ,'model':logreg_model_higher_tolerance\n",
    "        ,'X_test':X_test_final\n",
    "        ,'y_test':y_test\n",
    "    },\n",
    "    {\n",
    "        'name':'dummy_model'\n",
    "        ,'model':dummy_model\n",
    "        ,'X_test':X_test\n",
    "        ,'y_test':y_test\n",
    "    },\n",
    "    {\n",
    "        'name':'simple_logreg_model'\n",
    "        ,'model':simple_logreg_model\n",
    "        ,'X_test':X_test_no_transformations[[\"SibSp\", \"Parch\", \"Fare\"]]\n",
    "        ,'y_test':y_test\n",
    "    },\n",
    "    {\n",
    "        'name':'final_model'\n",
    "        ,'model':final_model\n",
    "        ,'X_test':X_test_selected\n",
    "        ,'y_test':y_test\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_dict = {\n",
    "    \"Model Name\": [candidate.get('name') for candidate in model_candidates],\n",
    "    \"Mean Accuracy\": [\n",
    "        candidate.get('model').score(\n",
    "                                candidate.get('X_test'), \n",
    "                                candidate.get('y_test')\n",
    "        ) \n",
    "        for candidate in model_candidates\n",
    "    ]\n",
    "    \n",
    "}\n",
    "final_scores_df = pd.DataFrame(final_scores_dict).set_index('Model Name')\n",
    "final_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final comparison of confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = round(len(model_candidates)/nrows)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "                nrows=nrows,\n",
    "                ncols=ncols,\n",
    "                figsize=(12, 6)\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Confusion Matrix Comparison\")\n",
    "\n",
    "\n",
    "for i,candidate in enumerate(model_candidates):\n",
    "    # Logic for making rows and columns for matrices\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    ax = axes[row][col]\n",
    "    \n",
    "    ax.set_title(candidate.get('name'))\n",
    "    plot_confusion_matrix(\n",
    "        candidate.get('model'),\n",
    "        candidate.get('X_test'),\n",
    "        candidate.get('y_test'),\n",
    "        ax=ax,\n",
    "        cmap=\"plasma\"\n",
    "    )\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot only the last models we created (so it's not too cluttered)\n",
    "for model_candidate in model_candidates[3:]:\n",
    "    plot_roc_curve(\n",
    "        model_candidate.get('model'),\n",
    "        model_candidate.get('X_test'),\n",
    "        model_candidate.get('y_test'), \n",
    "        name=model_candidate.get('name'),\n",
    "        ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the final model against the other earlier models\n",
    "plot_roc_curve(\n",
    "    final_model, \n",
    "    X_test_selected, \n",
    "    y_test,\n",
    "    name='final_model', \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "for model_candidate in model_candidates[:3]:\n",
    "    plot_roc_curve(\n",
    "        model_candidate.get('model'),\n",
    "        model_candidate.get('X_test'),\n",
    "        model_candidate.get('y_test'), \n",
    "        name=model_candidate.get('name'),\n",
    "        ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Build and iterate on a logistic regression model of **color** for the diamonds dataset! Maximize accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
