{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Model-Tuning\" data-toc-modified-id=\"Model-Tuning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model Tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameters\" data-toc-modified-id=\"Hyperparameters-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Difference-from-Parametric-/-Non-Parametric-Models\" data-toc-modified-id=\"Difference-from-Parametric-/-Non-Parametric-Models-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Difference from Parametric / Non-Parametric Models</a></span></li></ul></li><li><span><a href=\"#Data-Example\" data-toc-modified-id=\"Data-Example-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Prep\" data-toc-modified-id=\"Data-Prep-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Data Prep</a></span></li><li><span><a href=\"#Preparing-the-Test-Set\" data-toc-modified-id=\"Preparing-the-Test-Set-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Preparing the Test Set</a></span></li><li><span><a href=\"#Trying-Different-Models-&amp;-Values\" data-toc-modified-id=\"Trying-Different-Models-&amp;-Values-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Trying Different Models &amp; Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#$k$-Nearest-Neighbors-Model\" data-toc-modified-id=\"$k$-Nearest-Neighbors-Model-2.2.3.1\"><span class=\"toc-item-num\">2.2.3.1&nbsp;&nbsp;</span>$k$-Nearest Neighbors Model</a></span></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-2.2.3.2\"><span class=\"toc-item-num\">2.2.3.2&nbsp;&nbsp;</span>Decision Tree</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Automatically-Searching-with-Grid-Search\" data-toc-modified-id=\"Automatically-Searching-with-Grid-Search-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Automatically Searching with Grid Search</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#GridSearchCV\" data-toc-modified-id=\"GridSearchCV-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span><code>GridSearchCV</code></a></span></li><li><span><a href=\"#Choice-of-Grid-Values\" data-toc-modified-id=\"Choice-of-Grid-Values-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Choice of Grid Values</a></span></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Exercise</a></span></li></ul></li></ul></li><li><span><a href=\"#Better-Process:-Pipelines\" data-toc-modified-id=\"Better-Process:-Pipelines-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Better Process: Pipelines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Advantages-of-Pipeline\" data-toc-modified-id=\"Advantages-of-Pipeline-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Advantages of <code>Pipeline</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Reduces-Complexity\" data-toc-modified-id=\"Reduces-Complexity-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Reduces Complexity</a></span></li><li><span><a href=\"#Convenient\" data-toc-modified-id=\"Convenient-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Convenient</a></span></li><li><span><a href=\"#Flexible\" data-toc-modified-id=\"Flexible-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Flexible</a></span></li><li><span><a href=\"#Prevent-Mistakes\" data-toc-modified-id=\"Prevent-Mistakes-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Prevent Mistakes</a></span></li></ul></li><li><span><a href=\"#Example-of-Using-Pipeline\" data-toc-modified-id=\"Example-of-Using-Pipeline-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Example of Using <code>Pipeline</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Without-the-Pipeline-class\" data-toc-modified-id=\"Without-the-Pipeline-class-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Without the Pipeline class</a></span></li><li><span><a href=\"#With-Pipeline-Class\" data-toc-modified-id=\"With-Pipeline-Class-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>With <code>Pipeline</code> Class</a></span></li></ul></li><li><span><a href=\"#Grid-Searching-a-Pipeline\" data-toc-modified-id=\"Grid-Searching-a-Pipeline-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Grid Searching a Pipeline</a></span></li><li><span><a href=\"#A-Note-on-Data-Leakage\" data-toc-modified-id=\"A-Note-on-Data-Leakage-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>A Note on Data Leakage</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-of-leaking-information\" data-toc-modified-id=\"Example-of-leaking-information-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Example of leaking information</a></span></li><li><span><a href=\"#Example-of-Grid-Search-with-no-leakage\" data-toc-modified-id=\"Example-of-Grid-Search-with-no-leakage-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Example of Grid Search with no leakage</a></span></li></ul></li></ul></li><li><span><a href=\"#Extra:-Random-Searching\" data-toc-modified-id=\"Extra:-Random-Searching-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Extra: Random Searching</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#RandomizedSearchCV-with-LogisticRegression\" data-toc-modified-id=\"RandomizedSearchCV-with-LogisticRegression-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span><code>RandomizedSearchCV</code> with <code>LogisticRegression</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Grid-Search-Exercise\" data-toc-modified-id=\"Grid-Search-Exercise-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Grid Search Exercise</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as stats\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWBAT:\n",
    "\n",
    "- Explain what hyperparameters are\n",
    "- Describe the purpose of grid searching\n",
    "- Implement grid searching for the purposes of model optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the models we have looked at are really *families* of models in the sense that they make use of **hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters: solver for log reg, how many neighbors you put in, max splits\n",
    "\n",
    "Parameters describe the model, hyperparameter tells us how to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus for example the $k$-nearest-neighbors algorithm allows us to make:\n",
    "\n",
    "- a 1-nearest-neighbor model;\n",
    "- a 2-nearest-neighbors model;\n",
    "- a 3-nearest-neighbors model;\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, for another example, the decision tree algorithm allows us to make:\n",
    "\n",
    "- a classifier that branches according to information gain;\n",
    "- a classifier that branches according to Gini impurity;\n",
    "- a regressor that branches according to mean squared error;\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the sort of problem and data at hand, it is natural to experiment with different values of these hyperparameters to try to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can think of these **hyperparamters** as _dials_ of the base model\n",
    "\n",
    "<img width=60% src='images/dials.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Parameters of Log reg are coefficients, hyperparam is solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference from Parametric / Non-Parametric Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast the notion of hyperparameters with the distinction between parametric and non-parametric models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear regression model is parametric in the sense that we start with a given model *form* and we then search for the optimal parameters to fill in that form. But *those* parameters are not the sort we might tweak for the purposes of improving model performance. On the contrary, there is one best set of parameters, and the training of the model is a matter of finding those optimal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Penguins](https://raw.githubusercontent.com/allisonhorst/palmerpenguins/69530276d74b99df81cc385f4e95c644da69ebfa/man/figures/lter_penguins.png)\n",
    "\n",
    "> Images source: @allison_horst [github.com/allisonhorst/penguins](github.com/allisonhorst/penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "penguins = sns.load_dataset('penguins')\n",
    "\n",
    "penguins.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bill length & depth](https://raw.githubusercontent.com/allisonhorst/palmerpenguins/69530276d74b99df81cc385f4e95c644da69ebfa/man/figures/culmen_depth.png)\n",
    "\n",
    "> Images source: @allison_horst [github.com/allisonhorst/penguins](github.com/allisonhorst/penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to predict species given the other columns' values. Let's dummy-out `island` and `sex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = penguins.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins.pop('species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    penguins, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes('object')\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False)\n",
    "\n",
    "dums = ohe.fit_transform(X_train_cat)\n",
    "dums_df = pd.DataFrame(dums,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_train_cat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nums = X_train.select_dtypes('float64')\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train_nums)\n",
    "nums_df = pd.DataFrame(ss.transform(X_train_nums),\n",
    "                      index=X_train_nums.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_clean = pd.concat([nums_df, dums_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>x0_Dream</th>\n",
       "      <th>x0_Torgersen</th>\n",
       "      <th>x1_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.362748</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>-0.472344</td>\n",
       "      <td>-0.094599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.973499</td>\n",
       "      <td>-0.977375</td>\n",
       "      <td>1.408317</td>\n",
       "      <td>2.512546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.725152</td>\n",
       "      <td>0.445820</td>\n",
       "      <td>-0.472344</td>\n",
       "      <td>-1.185963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-1.221387</td>\n",
       "      <td>1.360731</td>\n",
       "      <td>-0.255345</td>\n",
       "      <td>-0.882806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.030757</td>\n",
       "      <td>0.954104</td>\n",
       "      <td>-0.110678</td>\n",
       "      <td>-0.519018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3  x0_Dream  x0_Torgersen  x1_Male\n",
       "160  0.362748  0.903276 -0.472344 -0.094599       1.0           0.0      0.0\n",
       "237  0.973499 -0.977375  1.408317  2.512546       0.0           0.0      1.0\n",
       "2   -0.725152  0.445820 -0.472344 -1.185963       0.0           1.0      0.0\n",
       "121 -1.221387  1.360731 -0.255345 -0.882806       0.0           1.0      1.0\n",
       "179  1.030757  0.954104 -0.110678 -0.519018       1.0           0.0      1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.94117647, 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=knn_model, X=X_train_clean,\n",
    "               y=y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat = X_test.select_dtypes('object')\n",
    "\n",
    "test_dums = ohe.transform(X_test_cat)\n",
    "test_dums_df = pd.DataFrame(test_dums,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                      index=X_test_cat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nums = X_test.select_dtypes('float64')\n",
    "\n",
    "test_nums = ss.transform(X_test_nums)\n",
    "test_nums_df = pd.DataFrame(test_nums,\n",
    "                           index=X_test_nums.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = pd.concat([test_nums_df,\n",
    "                 test_dums_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>x0_Dream</th>\n",
       "      <th>x0_Torgersen</th>\n",
       "      <th>x1_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.877839</td>\n",
       "      <td>-0.214949</td>\n",
       "      <td>-1.702007</td>\n",
       "      <td>-1.185963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>-1.282345</td>\n",
       "      <td>1.480650</td>\n",
       "      <td>0.784554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.381604</td>\n",
       "      <td>1.004932</td>\n",
       "      <td>-0.472344</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.088015</td>\n",
       "      <td>0.090021</td>\n",
       "      <td>-0.255345</td>\n",
       "      <td>-0.670597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.572464</td>\n",
       "      <td>0.547477</td>\n",
       "      <td>-0.689343</td>\n",
       "      <td>-0.215862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.221617</td>\n",
       "      <td>-0.977375</td>\n",
       "      <td>1.046651</td>\n",
       "      <td>0.936132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.649038</td>\n",
       "      <td>-1.079032</td>\n",
       "      <td>1.191318</td>\n",
       "      <td>0.875501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.439092</td>\n",
       "      <td>0.750790</td>\n",
       "      <td>-0.834009</td>\n",
       "      <td>-0.943437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.515436</td>\n",
       "      <td>-0.875718</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>1.118026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.267318</td>\n",
       "      <td>-1.739801</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.511713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3  x0_Dream  x0_Torgersen  x1_Male\n",
       "30  -0.877839 -0.214949 -1.702007 -1.185963       1.0           0.0      0.0\n",
       "317  0.534522 -1.282345  1.480650  0.784554       0.0           0.0      0.0\n",
       "79  -0.381604  1.004932 -0.472344 -0.276493       0.0           1.0      1.0\n",
       "201  1.088015  0.090021 -0.255345 -0.670597       1.0           0.0      0.0\n",
       "63  -0.572464  0.547477 -0.689343 -0.215862       0.0           0.0      1.0\n",
       "..        ...       ...       ...       ...       ...           ...      ...\n",
       "330  1.221617 -0.977375  1.046651  0.936132       0.0           0.0      0.0\n",
       "310  0.649038 -1.079032  1.191318  0.875501       0.0           0.0      0.0\n",
       "170  0.439092  0.750790 -0.834009 -0.943437       1.0           0.0      0.0\n",
       "229  0.515436 -0.875718  0.974318  1.118026       0.0           0.0      1.0\n",
       "232  0.267318 -1.739801  0.901985  0.511713       0.0           0.0      0.0\n",
       "\n",
       "[167 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Different Models & Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $k$-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880239520958084"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decreasing $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn5 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn5.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940119760479041"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn5.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.94117647, 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=knn5, X=X_train_clean,\n",
    "               y=y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = DecisionTreeClassifier(random_state=10)\n",
    "\n",
    "ct.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760479041916168"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.94117647, 0.94117647, 1.        ,\n",
       "       1.        , 0.875     , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=ct, X=X_train_clean,\n",
    "               y=y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing the branching criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = DecisionTreeClassifier(criterion='entropy',\n",
    "                          random_state=10)\n",
    "\n",
    "ct.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760479041916168"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically Searching with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not a bad idea to experiment with the values of your models' hyperparameters a bit as you're getting a feel for your models' performance. But there are more systematic ways of going about the search for optimal hyperparameters. One method of hyperparameter tuning is **grid searching**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to build multiple models with different hyperparameter values and then see which one performs the best. The hyperparameters and the values to try form a sort of *grid* along which we are looking for the best performance. For example:\n",
    "\n",
    "\n",
    "    1           | 'minkowski' | 'uniform'\n",
    "    3           | 'manhattan' | 'distance'\n",
    "    5           |\n",
    "    ______________________________________\n",
    "    n_neighbors | metric      | weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn has a [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class whose `fit()` method runs this procedure. Note that this can be quite computationally expensive since:\n",
    "\n",
    "- A model is constructed for each combination of hyperparameter values that we input; and\n",
    "- Each model is cross-validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "\n",
    "grid = {\n",
    "    'n_neighbors': [1, 3, 5],\n",
    "    'metric': ['minkowski', 'manhattan'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: How many models will we be constructing with this grid?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the grid search object with five-fold cross-validation\n",
    "\n",
    "gs = GridSearchCV(estimator=knn_model, param_grid=grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">You can set the scoring what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['minkowski', 'manhattan'],\n",
       "                         'n_neighbors': [1, 3, 5],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939393939393939"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940119760479041"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00284433, 0.00302901, 0.00306621, 0.00257316, 0.00245624,\n",
       "        0.00213866, 0.0022923 , 0.00225182, 0.00230474, 0.00288734,\n",
       "        0.00254865, 0.0022368 ]),\n",
       " 'std_fit_time': array([0.00053326, 0.00055377, 0.00084205, 0.00043145, 0.00059906,\n",
       "        0.00032464, 0.00039998, 0.00057001, 0.00038264, 0.00116871,\n",
       "        0.00067017, 0.00024083]),\n",
       " 'mean_score_time': array([0.00417676, 0.00335045, 0.00348835, 0.00265937, 0.00351315,\n",
       "        0.00241761, 0.00381427, 0.00260477, 0.00331097, 0.00236673,\n",
       "        0.00322623, 0.00211816]),\n",
       " 'std_score_time': array([0.00077397, 0.0005232 , 0.00043483, 0.00066409, 0.00109911,\n",
       "        0.00027607, 0.00197192, 0.00065898, 0.0006776 , 0.00056668,\n",
       "        0.00051718, 0.00029798]),\n",
       " 'param_metric': masked_array(data=['minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_neighbors': masked_array(data=[1, 1, 3, 3, 5, 5, 1, 1, 3, 3, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}],\n",
       " 'split0_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split1_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_score': array([0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697]),\n",
       " 'split3_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.99393939, 0.99393939, 0.99393939, 0.99393939, 0.99393939,\n",
       "        0.99393939, 0.99393939, 0.99393939, 0.99393939, 0.99393939,\n",
       "        0.99393939, 0.99393939]),\n",
       " 'std_test_score': array([0.01212121, 0.01212121, 0.01212121, 0.01212121, 0.01212121,\n",
       "        0.01212121, 0.01212121, 0.01212121, 0.01212121, 0.01212121,\n",
       "        0.01212121, 0.01212121]),\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 1, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 1, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 3, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 3, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 5, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 5, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 1, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 1, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5, 'wei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_metric  \\\n",
       "0        0.002844      0.000533         0.004177        0.000774    minkowski   \n",
       "1        0.003029      0.000554         0.003350        0.000523    minkowski   \n",
       "2        0.003066      0.000842         0.003488        0.000435    minkowski   \n",
       "3        0.002573      0.000431         0.002659        0.000664    minkowski   \n",
       "4        0.002456      0.000599         0.003513        0.001099    minkowski   \n",
       "5        0.002139      0.000325         0.002418        0.000276    minkowski   \n",
       "6        0.002292      0.000400         0.003814        0.001972    manhattan   \n",
       "7        0.002252      0.000570         0.002605        0.000659    manhattan   \n",
       "8        0.002305      0.000383         0.003311        0.000678    manhattan   \n",
       "9        0.002887      0.001169         0.002367        0.000567    manhattan   \n",
       "10       0.002549      0.000670         0.003226        0.000517    manhattan   \n",
       "11       0.002237      0.000241         0.002118        0.000298    manhattan   \n",
       "\n",
       "   param_n_neighbors param_weights  \\\n",
       "0                  1       uniform   \n",
       "1                  1      distance   \n",
       "2                  3       uniform   \n",
       "3                  3      distance   \n",
       "4                  5       uniform   \n",
       "5                  5      distance   \n",
       "6                  1       uniform   \n",
       "7                  1      distance   \n",
       "8                  3       uniform   \n",
       "9                  3      distance   \n",
       "10                 5       uniform   \n",
       "11                 5      distance   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'metric': 'minkowski', 'n_neighbors': 1, 'wei...                1.0   \n",
       "1   {'metric': 'minkowski', 'n_neighbors': 1, 'wei...                1.0   \n",
       "2   {'metric': 'minkowski', 'n_neighbors': 3, 'wei...                1.0   \n",
       "3   {'metric': 'minkowski', 'n_neighbors': 3, 'wei...                1.0   \n",
       "4   {'metric': 'minkowski', 'n_neighbors': 5, 'wei...                1.0   \n",
       "5   {'metric': 'minkowski', 'n_neighbors': 5, 'wei...                1.0   \n",
       "6   {'metric': 'manhattan', 'n_neighbors': 1, 'wei...                1.0   \n",
       "7   {'metric': 'manhattan', 'n_neighbors': 1, 'wei...                1.0   \n",
       "8   {'metric': 'manhattan', 'n_neighbors': 3, 'wei...                1.0   \n",
       "9   {'metric': 'manhattan', 'n_neighbors': 3, 'wei...                1.0   \n",
       "10  {'metric': 'manhattan', 'n_neighbors': 5, 'wei...                1.0   \n",
       "11  {'metric': 'manhattan', 'n_neighbors': 5, 'wei...                1.0   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 1.0           0.969697                1.0   \n",
       "1                 1.0           0.969697                1.0   \n",
       "2                 1.0           0.969697                1.0   \n",
       "3                 1.0           0.969697                1.0   \n",
       "4                 1.0           0.969697                1.0   \n",
       "5                 1.0           0.969697                1.0   \n",
       "6                 1.0           0.969697                1.0   \n",
       "7                 1.0           0.969697                1.0   \n",
       "8                 1.0           0.969697                1.0   \n",
       "9                 1.0           0.969697                1.0   \n",
       "10                1.0           0.969697                1.0   \n",
       "11                1.0           0.969697                1.0   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                 1.0         0.993939        0.012121                1  \n",
       "1                 1.0         0.993939        0.012121                1  \n",
       "2                 1.0         0.993939        0.012121                1  \n",
       "3                 1.0         0.993939        0.012121                1  \n",
       "4                 1.0         0.993939        0.012121                1  \n",
       "5                 1.0         0.993939        0.012121                1  \n",
       "6                 1.0         0.993939        0.012121                1  \n",
       "7                 1.0         0.993939        0.012121                1  \n",
       "8                 1.0         0.993939        0.012121                1  \n",
       "9                 1.0         0.993939        0.012121                1  \n",
       "10                1.0         0.993939        0.012121                1  \n",
       "11                1.0         0.993939        0.012121                1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of Grid Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which values should you pick for your grid? Intuitively, you should try both \"large\" and \"small\" values, but of course what counts as large and small will really depend on the type of hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a $k$-nearest neighbors model, 1 or 3 would be a small value for the number of neighbors and 15 or 17 would be a large value.\n",
    "- For a decision tree model, what counts as a small `max_depth` will really depend on the size of your training data. A `max_depth` of 5 would likely have little effect on a very small dataset but, at the same time, it would probably significantly decrease the variance of a model where the dataset is large.\n",
    "- For a logistic regression's regularization constant, you may want to try a set of values that are exponentially separated, like \\[1, 10, 100, 1000\\].\n",
    "- **If a grid search finds optimal values at the ends of your hyperparameter ranges, you might try another grid search with more extreme values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a grid search on a **decision tree model** of penguin species. What are the optimal values for the hyperparameters you've chosen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 3, 2],\n",
    "    'min_samples_split':[2, 10, 20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=dt, param_grid=grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 5, 3, 2],\n",
       "                         'min_samples_split': [2, 10, 20]})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760479041916168"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = gs.best_estimator_\n",
    "best_model.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Process: Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pipelines** can keep our code neat and clean all the way from gathering & cleaning our data, to creating models & fine-tuning them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgs.xkcd.com/comics/data_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Pipeline` class from [Scikit-Learn's API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) is especially convenient since it allows to use our other Estimators that we know and love!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduces Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can focus on parts of the pipeline at a time and debug or adjust parts as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can summarize your fine-detail steps into the pipeline. That way you can focus on the big-picture aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can also use pipelines to be applied to different models and can perform optimization techniques like grid search and random search on hyperparameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevent Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can focus on one section at a time.\n",
    ">\n",
    "> We also can ensure data leakage between our training and doesn't occur between our training dataset and validation/testing datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Using `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting some data\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without the Pipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformers (will adjust/massage the data)\n",
    "imputer = SimpleImputer(strategy=\"median\") # replaces missing values\n",
    "std_scaler = StandardScaler() # scales the data\n",
    "\n",
    "# Define the classifier (predictor) to train\n",
    "rf_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Have the classifer (and full pipeline) learn/train/fit from the data\n",
    "X_train_filled = imputer.fit_transform(X_train)\n",
    "X_train_scaled = std_scaler.fit_transform(X_train_filled)\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the trained classifier (still need to do the transformations)\n",
    "X_test_filled = imputer.transform(X_test)\n",
    "X_test_scaled = std_scaler.transform(X_test_filled)\n",
    "y_pred = rf_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that if we were to add more steps in this process, we'd have to change both the *training* and *testing* processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With `Pipeline` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), \n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('rf_clf', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "# Train the pipeline (tranformations & predictor)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the pipeline (includes the transfomers & trained predictor)\n",
    "predicted = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If we need to change our process, we change it _just once_ in the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Searching a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's first get our data prepared like we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins')\n",
    "penguins = penguins.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins.pop('species')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    penguins, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nums = X_train.select_dtypes('float64')\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train_nums)\n",
    "nums_df = pd.DataFrame(ss.transform(X_train_nums),\n",
    "                      index=X_train_nums.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes('object')\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False)\n",
    "\n",
    "dums = ohe.fit_transform(X_train_cat)\n",
    "dums_df = pd.DataFrame(dums,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_train_cat.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Intermediary step to treat categorical and numerical data differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "                \n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(drop='first',\n",
    "                         sparse=False))\n",
    "])\n",
    "\n",
    "trans = ColumnTransformer(transformers=[\n",
    "    ('numerical', numerical_pipeline, X_train_nums.columns),\n",
    "    ('categorical', categorical_pipeline, X_train_cat.columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = Pipeline(steps=[\n",
    "    ('trans', trans),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally showing we can fit the full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Performing grid search on the full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid = {'knn__n_neighbors': [3, 5, 7], 'knn__p': [1, 2, 3]}\n",
    "\n",
    "gs_pipe = GridSearchCV(estimator=model_pipe, param_grid=pipe_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_pipe.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Note on Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we still have to be careful in performing a grid search!\n",
    "\n",
    "We can accidentally \"leak\" information by doing transformations with the **whole data set**, instead of just the **training set**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of leaking information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Scales over all of the X-train data! (validation set will be considered in scaling)\n",
    "scaled_data = scaler.fit_transform(X_train.select_dtypes('float64'))\n",
    "\n",
    "parameters = {\n",
    "    'n_neighbors': [1, 3, 5],\n",
    "    'metric': ['minkowski', 'manhattan'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "clf_dt = KNeighborsClassifier()\n",
    "clf = GridSearchCV(clf_dt, parameters)\n",
    "clf.fit(X_train.select_dtypes('float64'), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Grid Search with no leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Note you use the part of the pipeline's name `NAME__{parameter}`\n",
    "parameters = {\n",
    "    'scaler__with_mean': [True, False],\n",
    "    'clf__n_neighbors': [1, 3, 5],\n",
    "    'clf__metric': ['minkowski', 'manhattan'],\n",
    "    'clf__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "cv.fit(X_train.select_dtypes('float64'), y_train)\n",
    "y_pred = cv.predict(X_test.select_dtypes('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Random Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to search for good hyperparameter values randomly. This is a nice choice if computation time is an issue or if you are tuning over continuous hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RandomizedSearchCV` with `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_grid = {'C': stats.uniform(loc=0, scale=10),\n",
    "               'l1_ratio': stats.expon(scale=0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(estimator=LogisticRegression(penalty='elasticnet',\n",
    "                                                    solver='saga',\n",
    "                                                    max_iter=1000,\n",
    "                                                    random_state=42),\n",
    "                        param_distributions=log_reg_grid,\n",
    "                       random_state=42)\n",
    "\n",
    "rs.fit(X_train_clean, y_train)\n",
    "\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Random Forest Classifier to predict the category of price range for the phones in this dataset. Try tuning some hyperparameters using a grid search, and then write up a short paragraph about your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "phones_test = pd.read_csv('data/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
