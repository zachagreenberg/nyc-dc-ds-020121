{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cross-Validation-&amp;-Regularization\" data-toc-modified-id=\"Cross-Validation-&amp;-Regularization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cross-Validation &amp; Regularization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Agenda\" data-toc-modified-id=\"Agenda-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Agenda</a></span></li></ul></li><li><span><a href=\"#When-a-Good-Model-Goes-Bad\" data-toc-modified-id=\"When-a-Good-Model-Goes-Bad-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>When a Good Model Goes Bad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bias-Variance-Tradeoff\" data-toc-modified-id=\"Bias-Variance-Tradeoff-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bias-Variance Tradeoff</a></span><ul class=\"toc-item\"><li><span><a href=\"#Aside:-Example-of-high-bias-and-variance\" data-toc-modified-id=\"Aside:-Example-of-high-bias-and-variance-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span><em>Aside: Example of high bias and variance</em></a></span></li><li><span><a href=\"#Underfitting\" data-toc-modified-id=\"Underfitting-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Underfitting</a></span></li><li><span><a href=\"#Overfitting\" data-toc-modified-id=\"Overfitting-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Overfitting</a></span></li></ul></li><li><span><a href=\"#How-Do-We-Identify-a-Bad-Model?-üïµÔ∏è\" data-toc-modified-id=\"How-Do-We-Identify-a-Bad-Model?-üïµÔ∏è-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>How Do We Identify a Bad Model? üïµÔ∏è</a></span><ul class=\"toc-item\"><li><span><a href=\"#Solution---Model-Validation\" data-toc-modified-id=\"Solution---Model-Validation-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Solution - Model Validation</a></span></li><li><span><a href=\"#Steps:\" data-toc-modified-id=\"Steps:-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Steps:</a></span></li><li><span><a href=\"#The-Power-of-the-Validation-Set\" data-toc-modified-id=\"The-Power-of-the-Validation-Set-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>The Power of the Validation Set</a></span><ul class=\"toc-item\"><li><span><a href=\"#From-Validation-to-Cross-Validation\" data-toc-modified-id=\"From-Validation-to-Cross-Validation-2.2.3.1\"><span class=\"toc-item-num\">2.2.3.1&nbsp;&nbsp;</span>From Validation to Cross-Validation</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Preventing-Overfitting---Regularization\" data-toc-modified-id=\"Preventing-Overfitting---Regularization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preventing Overfitting - Regularization</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Strategy-Behind-Ridge-/-Lasso-/-Elastic-Net\" data-toc-modified-id=\"The-Strategy-Behind-Ridge-/-Lasso-/-Elastic-Net-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Strategy Behind Ridge / Lasso / Elastic Net</a></span></li><li><span><a href=\"#Ridge-and-Lasso-Regression\" data-toc-modified-id=\"Ridge-and-Lasso-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Ridge and Lasso Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lasso:-L1-Regularization---Absolute-Value\" data-toc-modified-id=\"Lasso:-L1-Regularization---Absolute-Value-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Lasso: L1 Regularization - Absolute Value</a></span></li><li><span><a href=\"#Ridge:-L2-Regularization---Squared-Value\" data-toc-modified-id=\"Ridge:-L2-Regularization---Squared-Value-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Ridge: L2 Regularization - Squared Value</a></span></li><li><span><a href=\"#ü§î-Which-Do-I-Use?\" data-toc-modified-id=\"ü§î-Which-Do-I-Use?-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>ü§î Which Do I Use?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comparing-L1-&amp;-L2-Regularization\" data-toc-modified-id=\"Comparing-L1-&amp;-L2-Regularization-3.2.3.1\"><span class=\"toc-item-num\">3.2.3.1&nbsp;&nbsp;</span>Comparing L1 &amp; L2 Regularization</a></span></li></ul></li><li><span><a href=\"#The-Best-of-Both-Worlds:-Elastic-Net\" data-toc-modified-id=\"The-Best-of-Both-Worlds:-Elastic-Net-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>The Best of Both Worlds: Elastic Net</a></span></li></ul></li><li><span><a href=\"#Code-it-Out!\" data-toc-modified-id=\"Code-it-Out!-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Code it Out!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Producing-an-Overfit-Model\" data-toc-modified-id=\"Producing-an-Overfit-Model-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Producing an Overfit Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-3.3.1.1\"><span class=\"toc-item-num\">3.3.1.1&nbsp;&nbsp;</span>Train-Test Split</a></span></li><li><span><a href=\"#First-simple-model\" data-toc-modified-id=\"First-simple-model-3.3.1.2\"><span class=\"toc-item-num\">3.3.1.2&nbsp;&nbsp;</span>First simple model</a></span></li><li><span><a href=\"#Add-Polynomial-Features\" data-toc-modified-id=\"Add-Polynomial-Features-3.3.1.3\"><span class=\"toc-item-num\">3.3.1.3&nbsp;&nbsp;</span>Add Polynomial Features</a></span></li></ul></li><li><span><a href=\"#Ridge-(L2)-Regression\" data-toc-modified-id=\"Ridge-(L2)-Regression-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Ridge (L2) Regression</a></span></li><li><span><a href=\"#Cross-Validation-to-Optimize-the-Regularization-Hyperparameter\" data-toc-modified-id=\"Cross-Validation-to-Optimize-the-Regularization-Hyperparameter-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Cross Validation to Optimize the Regularization Hyperparameter</a></span><ul class=\"toc-item\"><li><span><a href=\"#Observation\" data-toc-modified-id=\"Observation-3.3.3.1\"><span class=\"toc-item-num\">3.3.3.1&nbsp;&nbsp;</span>Observation</a></span></li></ul></li><li><span><a href=\"#LEVEL-UP---Elastic-Net!\" data-toc-modified-id=\"LEVEL-UP---Elastic-Net!-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>LEVEL UP - Elastic Net!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Note-on-ElasticNet()\" data-toc-modified-id=\"Note-on-ElasticNet()-3.3.4.1\"><span class=\"toc-item-num\">3.3.4.1&nbsp;&nbsp;</span>Note on <code>ElasticNet()</code></a></span></li><li><span><a href=\"#Fitting-Regularized-Models-with-Cross-Validation\" data-toc-modified-id=\"Fitting-Regularized-Models-with-Cross-Validation-3.3.4.2\"><span class=\"toc-item-num\">3.3.4.2&nbsp;&nbsp;</span>Fitting Regularized Models with Cross-Validation</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression,\\\n",
    "LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, KFold,\\\n",
    "cross_val_score, cross_validate, ShuffleSplit\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation & Regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWBAT:\n",
    "\n",
    "- explain the notion of \"validation data\";\n",
    "- explain and use the algorithm of cross-validation;\n",
    "- explain the concept of regularization;\n",
    "- use Lasso and Ridge regularization in model design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the goals of a machine learning project is to make models which are highly predictive.\n",
    "If the model fails to generalize to unseen data then the model is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# When a Good Model Goes Bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> One of the goals of a machine learning project is to make models which are highly predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Adding complexity to a model can find patterns to help make better predictions! \n",
    "\n",
    "But too much complexity can lead to the model finding patterns in the noise..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Overfitting Model](images/overfitting_model_meme.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">So how do we know when our model is ~~a conspiracy theorist~~ overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. High bias\n",
    "    1. Systematic error in predictions --makes bad predictions, not finding real pattersn\n",
    "    2. Bias is about the strength of assumptions the model makes\n",
    "    3. **Underfit models tend to have high bias**\n",
    "2. High variance\n",
    "    1. The model is highly sensitive to changes in the data ie little noise\n",
    "    2. Overfit models tend to have low bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/bias_vs_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### _Aside: Example of high bias and variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "High bias is easy to wrap one's mind around: Imagine pulling three red balls from an urn that has hundreds of balls of all colors in a uniform distribution. Then my sample is a terrible representative of the whole population. If I were to build a model by extrapolating from my sample, that model would predict that _every_ ball produced would be red! That is, this model would be incredibly biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "High variance is a little bit harder to visualize, but it's basically the \"opposite\" of this. Imagine that the population of balls in the urn is mostly red, but also that there are a few balls of other colors floating around. Now imagine that our sample comprises a few balls, none of which is red. In this case, we've essentially picked up on the \"noise\", rather than the \"signal\". If I were to build a model by extrapolating from my sample, that model would be needlessly complex. It might predict that balls drawn before noon will be orange and that balls drawn after 8pm will be green, when the reality is that a simple model that predicted 'red' for all balls would be a superior model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The important idea here is that there is a *trade-off*: If we have too few data in our sample (training set), or too few predictors, we run the risk of high *bias*, i.e. an underfit model. On the other hand, if we have too many predictors (especially ones that are collinear), we run the risk of high *variance*, i.e. an overfit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Here](https://en.wikipedia.org/wiki/Overfitting#/media/File:Overfitting.svg) is a nice illustration of the difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Underfit models fail to capture all of the information in the data       \n",
    "Overall bad at predictions even on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* low complexity --> high bias, low variance\n",
    "* **training error: large\n",
    "* **testing error: large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Overfit models fit to the noise in the data and fail to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* high complexity --> low bias, high variance\n",
    "* **training error: low\n",
    "* **testing error: large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## How Do We Identify a Bad Model? üïµÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Solution - Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We want to validate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Generally speaking we want to take more precautions than using just a test and train split. After all, we're still imagining building just one model on the training set and then crossing our fingers for its performance on the test set.\n",
    "\n",
    "Data scientists often distinguish *three* subsets of data: **training, validation (dev), and testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Roughly:\n",
    "- Training data is for building the model;\n",
    "- Validation data is for *tweaking* the model it is a set comparing with the training;\n",
    "- Testing data is for evaluating the model on unseen data. We don't want to touch this until we agree on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Think of **training** data as what you study for a test\n",
    "- Think of **validation** data is using a practice test (note sometimes called **dev**)\n",
    "- Think of **testing** data as what you use to judge the model\n",
    "    - A **holdout** set is when your test dataset is never used for training (unlike in cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Split data into training data and a holdout test\n",
    "2. Design a model\n",
    "3. Evaluate how well it generalizes with **cross-validation** (only training data)\n",
    "4. Determine if we should adjust model, use cross-validation to evaluate, and repeat\n",
    "5. After iteratively adjusting your model, do a _final_ evaluation with the holdout test set\n",
    "6. DON'T TOUCH THE MODEL!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Having a small test set it maybe not the best example of what you'd see. You want your holdout to be representative of real world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The Power of the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This \"tweaking\" includes most of all the fine-tuning of model parameters (see below). Think of what this three-way distinction allows us to do:\n",
    "\n",
    "I can build a model on some data. Then, **before** I introduce the model to the testing data, I can introduce it to a different batch of data (the validation set). With respect to the validation data I can do things like measure error and tweak model parameters to minimize that error. Of course, I also don't want to lose sight of the error on the training data. If the model error has been minimized on the training error, then of course any changes I make to the model parameters will take me away from that minimum. But still the new information I've gained by looking at the model's performance on the validation data is valuable. I might for example go with a kind of compromising model whose parameters produce an error that's not too big on the training data and not too big on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question**: What's different about this procedure from what we've described before? Aren't I just calling the test data \"validation data\" now? Is there any substantive difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation allows us to tweak the model without touching the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### From Validation to Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since my model will \"see\" the validation data in any case, I might as well use *all* of my training data to validate my model! How do I do this?\n",
    "\n",
    "Cross-validation works like this: First I'll partition my training data into $k$-many *folds*. Then I'll train a model on $k-1$ of those folds and \"test\" it on the remaining fold. I'll do this for all possible divisions of my $k$ folds into $k-1$ training folds and a single \"testing\" fold. Since there are $k\\choose 1$$=k$-many ways of doing this, I'll be building $k$-many models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>40.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>42.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>215.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>216.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>32.1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>188.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>45.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>191.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "33      Adelie   Dream            40.9           18.9              184.0   \n",
       "244     Gentoo  Biscoe            42.9           13.1              215.0   \n",
       "330     Gentoo  Biscoe            50.5           15.2              216.0   \n",
       "142     Adelie   Dream            32.1           15.5              188.0   \n",
       "208  Chinstrap   Dream            45.2           16.6              191.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "33        3900.0    Male  \n",
       "244       5000.0  Female  \n",
       "330       5000.0  Female  \n",
       "142       3050.0  Female  \n",
       "208       3250.0  Female  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds = sns.load_dataset('penguins')\n",
    "birds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "birds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For simplicity's sake we'll limit our analysis to the numeric columns.\n",
    "\n",
    "numeric = birds[['bill_length_mm', 'bill_depth_mm',\n",
    "                 'flipper_length_mm', 'body_mass_g']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We'll drop the rows with null values\n",
    "\n",
    "numeric = numeric.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Suppose I want to model `body_mass_g` as a function of the other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = numeric.drop('body_mass_g', axis=1)\n",
    "y = numeric['body_mass_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll make ten models and record our evaluations of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X, \n",
    "                y=y,\n",
    "                estimator=lr2, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_r2', 'train_r2', 'test_neg_mean_squared_error', 'train_neg_mean_squared_error'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42725693,  0.34759891,  0.26457031,  0.18940771, -0.23644035,\n",
       "       -0.11124329,  0.64439272,  0.46668576,  0.70389366, -0.05362906])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.get('test_r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172805.4550294319, 52592.60213257134)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how we did compare the results?\n",
    "-1*cv_results.get('train_neg_mean_squared_error').mean(), (-1*cv_results.get('train_neg_mean_squared_error')).std()\n",
    "-1*cv_results.get('test_neg_mean_squared_error').mean(), (-1*cv_results.get('test_neg_mean_squared_error')).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172805.4550294319, 52592.60213257134)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*cv_results.get('test_neg_mean_squared_error').mean(), (-1*cv_results.get('test_neg_mean_squared_error')).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preventing Overfitting - Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again, complex models are very flexible in the patterns that they can model but this also means that they can easily find patterns that are simply statistical flukes of one particular dataset rather than patterns reflective of the underlying data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**When a model has large weights, the model is \"too confident\".** This translates to a model with high variance which puts it in danger of overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/punishing_model_metaphor.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to punish large (confident) weights by contributing them to the error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".cross_validate() will do multiple models to find the best\n",
    "after that you should probably do a .fit()  \n",
    ".fit() will find the best model for all you put in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Some Types of Regularization:**\n",
    "\n",
    "1. Reducing the number of features\n",
    "2. Increasing the amount of data\n",
    "3. Popular techniques: Ridge, Lasso, Elastic Net\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Strategy Behind Ridge / Lasso / Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Overfit models overestimate the relevance that predictors have for a target. Thus overfit models tend to have **overly large coefficients**. This is for reducing our coefficients.\n",
    "\n",
    "Generally, overfitting models come from a result of high model variance. High model variance can be caused by:\n",
    "\n",
    "- having irrelevant or too many predictors\n",
    "- multicollinearity\n",
    "- large coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The evaluation of many models, linear regression included, proceeds by measuring its **error**, some quantifiable expression of the discrepancy between its predictions and the ground truth. The best-fit line of LR, for example, minimizes the sum of squared residuals.\n",
    "\n",
    "Our new idea, then, will be ***to add a term representing the size of our coefficients to our loss function***. This will be our **cost function** $J$. How much error will our specific model have?\n",
    "\n",
    "The goal will still be to minimize this new function, but we can make progress toward this minimum *either* by reducing the size of our residuals *or* by reducing the size of our coefficients.\n",
    "\n",
    "Since coefficients can be either negative or positive, we have the familiar difficulty that we can't simply add them up to get a sense of how large they are in general. Once again there are two natural choices: We could focus either on the squares or the absolute values of the coefficients. The former strategy is the basis for **Ridge** (also called Tikhonov) regularization; the latter strategy results in **Lasso** (Least Absolute Shrinkage and Selection Operator) regularization.\n",
    "\n",
    "These tools, as we shall see, are easily implemented with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Regularization is about introducing a factor into our model designed to enforce the stricture that the coefficients stay small, by _penalizing_ the ones that get too large.\n",
    "\n",
    "That is, we'll alter our loss function so that the goal now is not merely to minimize the difference between actual values and our model's predicted values. Rather, we'll add in a term to our loss function that represents the sizes of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first problem is about picking up on noise rather than signal.\n",
    "The second problem is about having a least-squares estimate that is highly sensitive to random error.\n",
    "The third is about having highly sensitive predictors.\n",
    "\n",
    "Regularization is about introducing a factor into our model designed to enforce the stricture that the coefficients stay small, by penalizing the ones that get too large.\n",
    "\n",
    "That is, we'll alter our loss function so that the goal now is not merely to minimize the difference between actual values and our model's predicted values. Rather, we'll add in a term to our loss function that represents the sizes of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lasso: L1 Regularization - Absolute Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">if you suspect features are not import lasso may be better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Tend to get sparse vectors (small weights go to 0)\n",
    "- Reduce number of weights\n",
    "- Good feature selection to pick out importance\n",
    "\n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\dfrac{\\lambda}{m}|w_i| \\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">m is representing each individual example  \n",
    "L is the loss function -- can be mse  \n",
    "wi is the coefficient for the feature i  \n",
    "lambda is a hyperparameter - this means we change it to help the learning   \n",
    "if lambda is increases, the loss function is penalized    \n",
    "small weights(features) tend to go to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Ridge: L2 Regularization - Squared Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Not sparse vectors (weights homogeneous & small)\n",
    "- Tends to give better results for training\n",
    "\n",
    "    \n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\dfrac{\\lambda}{m}w_i^2 \\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ü§î Which Do I Use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Typically you'll want to use L2 regularization  \n",
    "\n",
    ">instead of getting rid of features, the coefficients will be relatively close to eachother. they likely will not go down to 0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- For a given value of $\\lambda$, the ridge makes for a gentler reining in of runaway coefficients. When in doubt, try ridge first.\n",
    "- The lasso will more quickly reduce the contribution of individual predictors down to insignificance. It is therefore most useful for trimming through the fat of datasets with many predictors or if a model with very few predictors is especially desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Comparing L1 & L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a bit subtle: \n",
    "- Consider vectors: [1,0] & [0.5, 0.5] \n",
    "- Recall we want smallest value for our value\n",
    "- L2 prefers [0.5,0.5] over [1,0] more homogeneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For a nice discussion of these methods in Python, see [this post](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The Best of Both Worlds: Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a combination of L1 and L2 regularization called the Elastic Net that can also be used. The idea is to use a scaled linear combination of the lasso and the ridge, where the weights add up to 100%. We might want 50% of each, but we also might want, say, 10% Lasso and 90% Ridge.\n",
    "\n",
    "The loss function for an Elastic Net Regression looks like this:\n",
    "\n",
    "Elastic Net:\n",
    "\n",
    "$\\rho\\Sigma^{n_{obs.}}_{i=1}[(y_i - \\Sigma^{n_{feat.}}_{j=0}\\beta_j\\times x_{ij})^2 + \\lambda\\Sigma^{n_{feat.}}_{j=0}|\\beta_j|] + (1 - \\rho)\\Sigma^{n_{obs.}}_{i=1}[(y_i - \\Sigma^{n_{feat.}}_{j=0}\\beta_j\\times x_{ij})^2 + \\lambda\\Sigma^{n_{feat.}}_{j=0}\\beta^2_j]$\n",
    "\n",
    "Sometimes you will see this loss function represented with different scaling terms, but the basic idea is to have a combination of L1 and L2 regularization terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Code it Out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Producing an Overfit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can often produce an overfit model by including **interaction terms**. We'll start over with the penguins dataset. This time we'll include the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "birds = birds.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#predicting the body mass\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        birds.drop('body_mass_g', axis=1),\n",
    "                                        birds['body_mass_g'],\n",
    "                                        random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>x0_Chinstrap</th>\n",
       "      <th>x0_Gentoo</th>\n",
       "      <th>x1_Dream</th>\n",
       "      <th>x1_Torgersen</th>\n",
       "      <th>x2_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>55.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>43.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>47.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>53.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm  bill_depth_mm  flipper_length_mm  x0_Chinstrap  \\\n",
       "321            55.9           17.0              228.0           0.0   \n",
       "265            43.6           13.9              217.0           0.0   \n",
       "36             38.8           20.0              190.0           0.0   \n",
       "308            47.5           14.0              212.0           0.0   \n",
       "191            53.5           19.9              205.0           1.0   \n",
       "\n",
       "     x0_Gentoo  x1_Dream  x1_Torgersen  x2_Male  \n",
       "321        1.0       0.0           0.0      1.0  \n",
       "265        1.0       0.0           0.0      0.0  \n",
       "36         0.0       1.0           0.0      1.0  \n",
       "308        1.0       0.0           0.0      0.0  \n",
       "191        0.0       1.0           0.0      1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking in other features (category)\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "dummies = ohe.fit_transform(X_train[['species', 'island', 'sex']])\n",
    "\n",
    "# Getting a DF\n",
    "dummies_df = pd.DataFrame(dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                         index=X_train.index)\n",
    "\n",
    "# What we'll feed int our model\n",
    "X_train_df = pd.concat([X_train[['bill_length_mm', 'bill_depth_mm',\n",
    "                                'flipper_length_mm']], dummies_df], axis=1)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our Test Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We are transforming the test data but NOT fitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note the same transformation (not FIT) to match structure\n",
    "test_dummies = ohe.transform(X_test[['species', 'island', 'sex']])\n",
    "test_df = pd.DataFrame(test_dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                       index=X_test.index)\n",
    "X_test_df = pd.concat([X_test[['bill_length_mm', 'bill_depth_mm',\n",
    "                              'flipper_length_mm']], test_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### First simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LinearRegression()\n",
    "lr1.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pens_preds = lr1.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8688983108974327"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.score(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's do some cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X_train_df, \n",
    "                y=y_train,\n",
    "                estimator=lr1, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_r2', 'train_r2', 'test_neg_mean_squared_error', 'train_neg_mean_squared_error'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86804859, 0.87184762, 0.86639447, 0.86902092, 0.86919768,\n",
       "       0.86625747, 0.86680671, 0.8768277 , 0.869645  , 0.86906114])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res = cv_results['train_r2']\n",
    "train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86092305, 0.68845759, 0.88730555, 0.85315477, 0.85555065,\n",
       "       0.88779582, 0.87796788, 0.71839192, 0.85080305, 0.86263277])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res = cv_results['test_r2']\n",
    "test_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We want them all to be similar to train and similar to eachother. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934228693424332"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.score(X_test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253.98121177477847"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(pens_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Add Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=3)\n",
    "X_poly_train = pf.fit_transform(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_lr = LinearRegression()\n",
    "poly_lr.fit(X_poly_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929837700747567"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_lr.score(X_poly_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X_poly_train, \n",
    "                y=y_train,\n",
    "                estimator=poly_lr, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81274494, 0.90586696, 0.8712185 , 0.86791379, 0.87630344,\n",
       "       0.89249435, 0.87772829, 0.89532593, 0.91414692, 0.80533062])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res = cv_results['train_r2']\n",
    "train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58415875, -0.98181945,  0.5788373 ,  0.67200794,  0.13603484,\n",
       "        0.51348527,  0.11073339,  0.17470108,  0.81904844,  0.56611478])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res = cv_results['test_r2']\n",
    "test_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_poly_test = pf.transform(X_test_df)\n",
    "poly_preds = poly_lr.predict(X_poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poly_lr.score(X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(poly_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Ridge (L2) Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You want to scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# You should always be sure to _standardize_ your data before\n",
    "# applying regularization!\n",
    "\n",
    "X_train_processed = pf.fit_transform(ss.fit_transform(X_train_df))\n",
    "X_test_processed = pf.transform(ss.transform(X_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Lambda' is the standard variable for the strength of the\n",
    "# regularization (as in the above formulas), but since lambda\n",
    "# is a key word in Python, these sklearn regularization tools\n",
    "# use 'alpha' instead.\n",
    "\n",
    "rr = Ridge(alpha=10, random_state=42)\n",
    "\n",
    "rr.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996018638606075"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.score(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X_train_processed, \n",
    "                y=y_train,\n",
    "                estimator=rr, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9032693 , 0.90324528, 0.9035933 , 0.89891272, 0.90272743,\n",
       "       0.90131551, 0.90217371, 0.90264219, 0.90033615, 0.90105874])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['train_r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82580809, 0.65814935, 0.81394732, 0.87312394, 0.81693461,\n",
       "       0.86570275, 0.83985607, 0.79060346, 0.871485  , 0.86183286])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_r2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ridge_preds = rr.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838077293450028"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.score(X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313.05702682531415"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(ridge_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Much better! But how do we know which value of `alpha` to pick?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cross Validation to Optimize the Regularization Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The regularization strength could sensibly be any nonnegative number, so there's no way to check \"all possible\" values. It's often useful to try several values that are different orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you should be using cross validation\n",
    "# X_valid, ... = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alphas = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    rr.fit(X_train_processed, y_train)\n",
    "    train_score = rr.score(X_train_processed, y_train)\n",
    "    test_score = rr.score(X_test_processed, y_test)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge $R^2$ as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.plot(alphas, train_scores, label='train')\n",
    "ax.plot(alphas, test_scores, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">a good rule for lambda is doing powers of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It looks like the best value is somewhere around 100. If we wanted more precision, we could repeat the same sort of exercise with a set of alphas nearer to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice how the values increase but then decrease? Regularization helps with overfitting, but if the strength of the regularization becomes too great, then large coefficients will be punished more than they really should. What happens then is that the original error between truth and model predictions becomes neglected as a quantity to be minimized, and the bias of the model begins to outweigh its variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LEVEL UP - Elastic Net!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Naturally, the Elastic Net has the same interface through sklearn as the other regularization tools! The only difference is that we now have to specify how much of each regularization term we want. The name of the parameter for this (represented by $\\rho$ above) in sklearn is `l1_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha=10, l1_ratio=0.1, random_state=42)\n",
    "\n",
    "enet.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enet.score(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enet.score(X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setting the `l1_ratio` to 1 is equivalent to the lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratios = np.linspace(0.01, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for ratio in ratios:\n",
    "    enet = ElasticNet(alpha=100, l1_ratio=ratio, random_state=42)\n",
    "    enet.fit(X_train_processed, y_train)\n",
    "    preds.append(enet.predict(X_test_processed[0].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "lasso = Lasso(alpha=100, random_state=42)\n",
    "lasso.fit(X_train_processed, y_train)\n",
    "lasso_pred = lasso.predict(X_test_processed[0].reshape(1, -1))\n",
    "\n",
    "ax.plot(ratios, preds, label='elastic net')\n",
    "ax.scatter(1, lasso_pred, c='k', s=70, label='lasso')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Note on `ElasticNet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is an Elastic Net with `l1_ratio` set to 0 equivalent to the ridge? In theory yes. But in practice no. It looks like the `ElasticNet()` predictions on the first test data point as `l1_ratio` shrinks are tending toward some value around 3400. Let's check to see what prediction `Ridge()` gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10, random_state=42)\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "ridge.predict(X_test_processed[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you check the docstring for the `ElasticNet()` class you will see:\n",
    "- that the function being minimized is slightly different from what we saw above; and\n",
    "- that the results are unreliable when `l1_ratio` $\\leq 0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Exercise**: Visualize the difference in this case between `ElasticNet(l1_ratio=0.01)` and `Ridge()` by making a scatterplot of each model's predicted values for the first ten points in `X_test_processed`. Use `alpha=10` for each model.\n",
    "\n",
    "        Level Up: Make a second scatterplot that compares the predictions on the same data\n",
    "        points between ElasticNet(l1_ratio=1) and Lasso()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    <code>fig, ax = plt.subplots()\n",
    "enet_r = ElasticNet(alpha=10, l1_ratio=0.01, random_state=42)\n",
    "enet_r.fit(X_train_processed, y_train)\n",
    "preds_enr = enet_r.predict(X_test_processed[:10])\n",
    "preds_ridge = ridge.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enr)\n",
    "ax.scatter(np.arange(10), preds_ridge);</code>  \n",
    "        </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        Level Up\n",
    "    </summary>\n",
    "<code>fig, ax = plt.subplots()\n",
    "enet_l = ElasticNet(alpha=10, l1_ratio=1, random_state=42)\n",
    "enet_l.fit(X_train_processed, y_train)\n",
    "preds_enl = enet_l.predict(X_test_processed[:10])\n",
    "preds_lasso = lasso.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enl)\n",
    "ax.scatter(np.arange(10), preds_lasso);</code>\n",
    "    </details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Fitting Regularized Models with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our friend `sklearn` also includes tools that fit regularized regressions *with cross-validation*: `LassoCV`, `RidgeCV`, and `ElasticNetCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Exercise**: Use `RidgeCV` to fit a seven-fold cross-validated ridge regression model to our `X_train_processed` data and then calculate $R^2$ and the RMSE (root-mean-squared error) on our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        Answer\n",
    "    </summary>\n",
    "    <code>rcv = RidgeCV(cv=7)\n",
    "rcv.fit(X_train_processed, y_train)\n",
    "rcv.score(X_test_processed, y_test)\n",
    "np.sqrt(mean_squared_error(y_test, rcv.predict(X_test_processed)))</code>\n",
    "    </details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "47px",
    "left": "46px",
    "top": "175px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
