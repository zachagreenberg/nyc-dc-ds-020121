{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "When trying to understand your data, it is typically impossible to just look at raw data and get much insight. We need ways to turn a bunch of data into a smaller set of numbers that are easily digestible summaries of your data. This will make them understandable both for you and for the people you work with. We call these **descriptive statistics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "- Use measures of center and spread to describe data\n",
    "- Use histograms and box-and-whisker plots to describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of our data table's columns has a bunch of values. We might have a set of body temperatures or house prices or birth rates or frog leg lengths. How, in general, can we characterize such a set of numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple dataset, based on a hypothetical survey of the number of pairs of shoes owned by 11 random people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([5, 6, 3, 4, 3, 4, 8, 8, 1, 8, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has a bunch of individual observations in a range of values. These observations have an **empirical distribution** describing how the values are distributed across this range. We'll shorten this to just **distribution** for now. Everything that follows is our attempt to understand the distribution of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Center\n",
    "\n",
    "One natural place to begin is to ask about where the **middle** of the data is. In other words, what is the value that is closest to our other values? \n",
    "\n",
    "There are three common measures used to describe the \"middle\":\n",
    "\n",
    "- **Mean**: The sum of values / number of values\n",
    "- **Median**: The value with as many values above it as below it\n",
    "    - If the dataset has an even number of values, the median is the mean of the two middle numbers.\n",
    "- **Mode**: The most frequent value(s)\n",
    "    - A dataset can have multiple modes if multiple values are tied for the most frequent.\n",
    "\n",
    "Let's see what we have for our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {np.mean(data)}\")\n",
    "print(f\"Median: {np.median(data)}\")\n",
    "print(f\"Mode: {stats.mode(data)[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can also find the mode(s) using np.unique()\n",
    "counts = np.unique(data, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: If somebody asked you \"How many pairs of shoes do people usually have?\", how would you answer (based on these data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean $\\bar{x}$ is the point that minimizes the *sum of squared differences* for a given set of data.\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        Proof\n",
    "    </summary>\n",
    "    We want to find the point $k$ that minimizes $L(k) = \\Sigma^n_{i=1}(x_i-k)^2$. Now, a calculus trick, which we'll see again: To find the minimum of a function, we'll set its derivative to 0. Taking the derivative, we have:\n",
    "\n",
    "$L'(k) = -2\\Sigma^n_{i=1}(x_i-k)$.\n",
    "\n",
    "Now we solve $L'(k) = 0$ for $k$:\n",
    "\n",
    "$-2\\Sigma^n_{i=1}(x_i-k) = 0$, so <br/><br/>\n",
    "$\\Sigma^n_{i=1}(x_i-k) = 0$, so <br/><br/>\n",
    "$\\Sigma^n_{i=1}x_i = \\Sigma^n_{i=1}k = nk$, so <br/><br/>\n",
    "$k = \\frac{\\Sigma^n_{i=1}x_i}{n} = \\bar{x}$.\n",
    "    </details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, the median is the point that minimizes the *sum of absolute differences*.\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "    Proof\n",
    "    </summary>\n",
    "    We want to find the point $k$ that minimizes $D(k) = \\Sigma^n_{i=1}|x_i-k|$. Taking the derivative, we have:\n",
    "\n",
    "$D'(k) = \\Sigma^n_{i=1}\\frac{k-x_i}{|k-x_i|}$.\n",
    "\n",
    "Now we solve $D'(k) = 0$ for $k$:\n",
    "\n",
    "Consider the sum $\\Sigma^n_{i=1}\\frac{k-x_i}{|k-x_i|} = 0$. Ignoring the case where $k = x_i$, each of the addends in this sum is $1$ if $k\\geq x_i$ and $-1$ if not. To make this sum equal to 0, we thus want to choose $k$ such that there are the same number of $1$s and $-1$s, which means that we want to choose $k$ to be the middle number, i.e. the median.\n",
    "\n",
    "Notes:\n",
    "- if $n$ is odd, then the minimum of the function occurs not where its derivative is 0 but where it is *undefined*;\n",
    "- if $n$ is even, then *any* number between the two middle numbers will minimize our function:\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Spread\n",
    "\n",
    "Another natural question is about the **spread** of the data. In other words, how wide a range of values do you have? And how close or far are they from the \"middle\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min, Max, and Range\n",
    "\n",
    "The minumun and maximum values of a dataset tell you the full extent of the values of your dataset. The range of the dataset is the difference between those two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min: {data.min()}\")\n",
    "print(f\"Max: {data.max()}\")\n",
    "print(f\"Range: {data.max() - data.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles and IQR\n",
    "\n",
    "You can also calculate values at various **percentiles** to understand the spread. An \"Nth Percentile\" value is the value that is greater than N% of other values. The 25th and 75th percentiles are commonly used to describe spread, and the **interquartile range (IQR)** is the difference between these two values.\n",
    "\n",
    "See [the docs](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) for more specifics about how percentiles are calculated, which is suprisingly tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"25th Percentile: {np.percentile(data, 25)}\")\n",
    "print(f\"75th Percentile: {np.percentile(data, 75)}\")\n",
    "print(f\"IQR: {np.percentile(data, 75) - np.percentile(data, 25)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation\n",
    "\n",
    "The **standard deviation** is a measure of how far away values are from the mean. It is usually calculated as $\\sqrt\\frac{\\Sigma(x_i - \\bar{x})^2}{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Standard Deviation: {data.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with percentiles, there are different ways that standard deviation is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data, columns=[\"Pairs of Shoes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: If somebody asked you \"How much do people differ in the number of pairs of shoes they have?\", how would you answer (based on these data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df.describe()\n",
    "\n",
    "You can actually get a bunch of descriptive statistics from any `pandas` DataFrame using the `.describe()` method. This should be one of the first things you'll do when exploring a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Description\n",
    "\n",
    "A picture is worth a thousand words - or numbers! Here we will show how to use histograms and box-and-whisker plots to describe your data.\n",
    "\n",
    "## Histograms\n",
    "\n",
    "One natural way of starting to understand a dataset is to construct a **histogram**, which is a bar chart showing the counts of the different values in the dataset.\n",
    "\n",
    "There will usually be many distinct values in your dataset, and you will need to decide how many **bins** to use in the histogram. The bins define the ranges of values captured in each bar in your chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=14)\n",
    "plt.title('Counts, 14 Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=10)\n",
    "plt.title('Counts, 10 Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=5)\n",
    "plt.title('Counts, 5 Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=8)\n",
    "plt.title('Counts, 8 Bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box and Whisker\n",
    "\n",
    "A box-and-whisker plot can also be useful for visually summarizing your data by showing the min, IQR, and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data)\n",
    "plt.title('Counts of Pairs of Shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Shape Descriptors\n",
    "\n",
    "Here are a few other ways that people describe the distributions of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skew\n",
    "\n",
    "**Skewness**, also known as **skew**, is a measure of **asymmetry**. Specifically, it measures how much your distribution is weighted toward one side. \n",
    "\n",
    "**Right skew**, also known as **positive skew**, means that your distribution has more extreme values on the high end than on the low end.\n",
    "\n",
    "**Left skew**, also known as **negative skew**, means that your distribution has more extreme values on the low end than on the high end.\n",
    "\n",
    "Skewness of 0 represents a distribution with equal weight on both sides. There are multiple ways to calculate skew, but values between -1 and 1 are usually considered low.\n",
    "\n",
    "![skew](https://upload.wikimedia.org/wikipedia/commons/c/cc/Relationship_between_mean_and_median_under_different_skewness.png)\n",
    "Diva Jain, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis\n",
    "\n",
    "**Kurtosis** is a measure of how heavy the tails are. You can also think of it in terms of how pointy the peak is.\n",
    "\n",
    "Usually kurtosis is calculated in reference to a **normal distribution**, which we'll learn more about later in the course. We usually calculate **excess kurtosis** to see if a distribution has more or less kurtosis than a normal distribution (in dots below). \n",
    "\n",
    "Excess kurtosis of 0 means that the tails have similar weight to the tails of a normal distribution. Positive values mean heavier tails than normal, negative values mean lighter tails than normal.\n",
    "\n",
    "![kurt](images/positive-kurtosis.jpg)\n",
    "[Simple Psychology](https://www.simplypsychology.org/kurtosis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Moments\n",
    "\n",
    "Mean, standard deviation, skewness, and kurtosis are all called **moments** in statistics. If you're interested, you can learn more about these [here](https://www.statisticshowto.datasciencecentral.com/what-is-a-moment/) or [here](https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality\n",
    "\n",
    "Distributions can have different **modality**. This relates to whether the distribution has distinct peaks and, if so, how many peaks there are and how strong they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 40)\n",
    "y = stats.uniform.pdf(X) + 0.05 * np.random.rand(40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.plot(X, y, lw=5)\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.title('Flat Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-5, 5, 40)\n",
    "y = stats.norm.pdf(X, loc=0) \\\n",
    "+ 0.05 * np.random.rand(40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.plot(X, y, lw=5)\n",
    "plt.title('Unimodal Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-5, 5, 40)\n",
    "y = stats.norm.pdf(X, loc=-2) + stats.norm.pdf(X, loc=2)\\\n",
    "+ 0.05 * np.random.rand(40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.plot(X, y, lw=5)\n",
    "plt.title('Bimodal Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rock Music Data\n",
    "\n",
    "Let's see what stats or graphs we can pull out of this dataset about rock songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "songs = pd.read_csv('classic-rock-song-list.csv')\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity**: Describe the `PlayCount` variable using...\n",
    "\n",
    "- `.describe()`\n",
    "- A histogram\n",
    "\n",
    "Summarize the distribution of the data in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        Answer Code\n",
    "    </summary>\n",
    "    \n",
    "    songs['PlayCount'].describe()\n",
    "    \n",
    "    songs['PlayCount'].hist()\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Up: Rock Artist Analysis\n",
    "\n",
    "We might also try grouping by artist and analyzing the counts of their songs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_song_counts = songs.groupby('ARTIST CLEAN')\\\n",
    "                          .count()['Song Clean']\\\n",
    "                          .sort_values(ascending=False)\n",
    "\n",
    "artist_song_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.bar(artist_song_counts[:10].index, artist_song_counts[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_song_counts.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Up: Iris Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_data.data\n",
    "y = iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation for this dataset\n",
    "\n",
    "# print(iris_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(np.hstack([X, y.reshape(-1, 1)]),\n",
    "                  columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['spec'] = iris_df['spec'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    "iris_df['spec'] = iris_df['spec'].map(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms Across Groups\n",
    "\n",
    "Let's create histograms for each of our flower groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_df[iris_df['spec'] == 'setosa']['sepal_wid'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df[iris_df['spec'] == 'versicolor']['sepal_wid'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df[iris_df['spec'] == 'virginica']['sepal_wid'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to visualize the three histograms together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This is not a good visualization\n",
    "\n",
    "iris_df.groupby('spec')['sepal_wid'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Plots\n",
    "\n",
    "### Swarm Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"spec\", y=\"sepal_wid\",\n",
    "            kind='swarm', data=iris_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='sepal_wid', y='spec',\n",
    "            kind='violin', data=iris_df);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
